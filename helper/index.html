
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../examples/">
      
      
        <link rel="next" href="../paper_table/">
      
      
      <link rel="icon" href="../assets/logo.svg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.18">
    
    
      
        <title>Helper - awesome-social-agents</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.66ac8b77.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#environmentslanguage" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="awesome-social-agents" class="md-header__button md-logo" aria-label="awesome-social-agents" data-md-component="logo">
      
  <img src="../assets/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            awesome-social-agents
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Helper
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="teal"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/sotopia-lab/awesome-social-agents" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    awesome-social-agents
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../contribution/" class="md-tabs__link">
        
  
    
  
  Contribution

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../examples/" class="md-tabs__link">
        
  
    
  
  Examples

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Helper

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../paper_table/" class="md-tabs__link">
        
  
    
  
  Paper table

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../taxonomy/" class="md-tabs__link">
        
  
    
  
  Tags that you can add to each field

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="awesome-social-agents" class="md-nav__button md-logo" aria-label="awesome-social-agents" data-md-component="logo">
      
  <img src="../assets/logo.svg" alt="logo">

    </a>
    awesome-social-agents
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/sotopia-lab/awesome-social-agents" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    awesome-social-agents
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../contribution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contribution
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Examples
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Helper
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Helper
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#environmentslanguage" class="md-nav__link">
    <span class="md-ellipsis">
      environments/language
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environmentsembodied" class="md-nav__link">
    <span class="md-ellipsis">
      environments/embodied
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environmentsvirtual" class="md-nav__link">
    <span class="md-ellipsis">
      environments/virtual
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environmentsrobotics" class="md-nav__link">
    <span class="md-ellipsis">
      environments/robotics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelingin-context-learning" class="md-nav__link">
    <span class="md-ellipsis">
      modeling/in-context-learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelingfinetuning" class="md-nav__link">
    <span class="md-ellipsis">
      modeling/finetuning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelingreinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      modeling/reinforcement-learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationlanguage" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/language
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationembodied" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/embodied
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationvirtual" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/virtual
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationrobotics" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/robotics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionstext" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/text
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionsembodied" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/embodied
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionsrobot" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionshuman" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/human
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#applicationshealth" class="md-nav__link">
    <span class="md-ellipsis">
      applications/health
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#applicationspolicy" class="md-nav__link">
    <span class="md-ellipsis">
      applications/policy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concernsrisks" class="md-nav__link">
    <span class="md-ellipsis">
      concerns/risks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concernssafety" class="md-nav__link">
    <span class="md-ellipsis">
      concerns/safety
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../paper_table/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Paper table
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../taxonomy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tags that you can add to each field
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#environmentslanguage" class="md-nav__link">
    <span class="md-ellipsis">
      environments/language
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environmentsembodied" class="md-nav__link">
    <span class="md-ellipsis">
      environments/embodied
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environmentsvirtual" class="md-nav__link">
    <span class="md-ellipsis">
      environments/virtual
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environmentsrobotics" class="md-nav__link">
    <span class="md-ellipsis">
      environments/robotics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelingin-context-learning" class="md-nav__link">
    <span class="md-ellipsis">
      modeling/in-context-learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelingfinetuning" class="md-nav__link">
    <span class="md-ellipsis">
      modeling/finetuning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modelingreinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      modeling/reinforcement-learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationlanguage" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/language
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationembodied" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/embodied
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationvirtual" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/virtual
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluationrobotics" class="md-nav__link">
    <span class="md-ellipsis">
      evaluation/robotics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionstext" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/text
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionsembodied" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/embodied
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionsrobot" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactionshuman" class="md-nav__link">
    <span class="md-ellipsis">
      interactions/human
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#applicationshealth" class="md-nav__link">
    <span class="md-ellipsis">
      applications/health
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#applicationspolicy" class="md-nav__link">
    <span class="md-ellipsis">
      applications/policy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concernsrisks" class="md-nav__link">
    <span class="md-ellipsis">
      concerns/risks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concernssafety" class="md-nav__link">
    <span class="md-ellipsis">
      concerns/safety
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Helper</h1>

<p>[July, 2023] <a href="https://arxiv.org/abs/2307.07924">Communicative Agents for Software Development</a>, Chen Qian et al., arXiv</p>
<h3 id="environmentslanguage">environments/language<a class="headerlink" href="#environmentslanguage" title="Permanent link"></a></h3>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.04132">Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference</a>, Wei-Lin Chiang et al., arXiv preprint arXiv:2403.04132</p>
<p>[August, 2023] <a href="https://arxiv.org/abs/2308.07540">{CALYPSO}: {LLMs} as Dungeon Masters' Assistants</a>, Andrew Zhu et al., The 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE 2023)</p>
<p>[July, 2023] <a href="https://aclanthology.org/2023.acl-long.624">{I} Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons</a>, Zhou et al., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</p>
<p>[July, 2023] <a href="https://aclanthology.org/2023.acl-long.229">{FIREBALL}: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information</a>, Zhu et al., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</p>
<p>[March, 2023] <a href="https://github.com/ini/multigrid">Fast Multi-Agent Gridworld Environments for Gymnasium</a>, Ini Oguntola et al., GitHub</p>
<p>[December, 2022] <a href="https://aclanthology.org/2022.emnlp-main.637">Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence</a>, Callison-Burch et al., Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</p>
<p>[November, 2022] <a href="https://www.science.org/doi/full/10.1126/science.ade9097">Human-level play in the game of Diplomacy by combining language models with strategic reasoning</a>, Meta Fundamental AI Research Diplomacy Team (FAIR)† et al., Science</p>
<p>[November, 2022] <a href="https://openai.com/blog/chatgpt">Introducing ChatGPT</a>, OpenAI et al., n/a</p>
<p>[August, 2022] <a href="https://arxiv.org/abs/2208.03188">Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage</a>, Kurt Shuster et al., arXiv preprint arXiv:2208.03188</p>
<p>[May, 2022] <a href="https://arxiv.org/abs/2205.01068">Opt: Open pre-trained transformer language models</a>, Susan Zhang et al., arXiv preprint arXiv:2205.01068</p>
<p>[July, 2020] <a href="https://aclanthology.org/2020.acl-main.353">It Takes Two to Lie: One to Lie, and One to Listen</a>, Peskov et al., Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</p>
<p>[March, 2020] <a href="http://dx.doi.org/10.1016/j.artint.2019.103216">The Hanabi challenge: A new frontier for AI research</a>, Nolan Bard et al., Artificial Intelligence</p>
<p>[March, 2020] <a href="https://aclanthology.org/2020.cl-1.2">The Design and Implementation of {X}iao{I}ce, an Empathetic Social Chatbot</a>, Zhou et al., Computational Linguistics</p>
<p>[August, 2019] <a href="http://arxiv.org/abs/1908.09453">{OpenSpiel}: A Framework for Reinforcement Learning in Games</a>, Marc Lanctot et al., CoRR</p>
<p>[July, 2019] <a href="https://aclanthology.org/P19-1566">Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</a>, Wang et al., Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</p>
<p>[July, 2019] <a href="https://github.com/datamllab/rlcard">RLCard: A Toolkit for Reinforcement Learning in Card Games</a>, Daochen Zha et al., arXiv preprint arXiv:1910.04376</p>
<p>[April, 2019] <a href="https://openreview.net/forum?id=r1l73iRqKm">Wizard of Wikipedia: Knowledge-Powered Conversational Agents</a>, Emily Dinan et al., International Conference on Learning Representations</p>
<p>[October, 2018] <a href="https://aclanthology.org/D18-1256">Decoupling Strategy and Generation in Negotiation Dialogues</a>, He et al., Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</p>
<p>[April, 2018] <a href="https://ojs.aaai.org/index.php/AAAI/article/view/11977">A knowledge-grounded neural conversation model</a>, Marjan Ghazvininejad et al., Proceedings of the AAAI Conference on Artificial Intelligence</p>
<p>[March, 2018] <a href="https://link.springer.com/chapter/10.1007/978-3-319-75487-1_14">Towards empathetic human-robot interactions</a>, Pascale Fung et al., Computational Linguistics and Intelligent Text Processing: 17th International Conference, CICLing 2016, Konya, Turkey, April 3--9, 2016, Revised Selected Papers, Part II 17</p>
<p>[September, 2017] <a href="https://aclanthology.org/D17-1259">Deal or No Deal? End-to-End Learning of Negotiation Dialogues</a>, Lewis et al., Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</p>
<p>[August, 2016] <a href="https://aclanthology.org/P16-1094/">A persona-based neural conversation model</a>, Jiwei Li et al., arXiv preprint arXiv:1603.06155</p>
<p>[November, 2009] <a href="https://link.springer.com/chapter/10.1007/978-1-4020-6710-5_13">The anatomy of ALICE</a>, Richard S Wallace et al., n/a</p>
<p>[January, 2006] <a href="https://link.springer.com/chapter/10.1007/11825890_3">Empathic computing</a>, Yang Cai et al., Ambient intelligence in everyday life: Foreword by Emile Aarts</p>
<p>[January, 1966] <a href="https://doi.org/10.1145/365153.365168">ELIZA—a computer program for the study of natural language communication between man and machine</a>, Joseph Weizenbaum et al., Commun. ACM</p>
<h3 id="environmentsembodied">environments/embodied<a class="headerlink" href="#environmentsembodied" title="Permanent link"></a></h3>
<p>[October, 2024] <a href="https://openreview.net/forum?id=4znwzG92CE">Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots</a>, Xavier Puig et al., The Twelfth International Conference on Learning Representations</p>
<p>[April, 2024] <a href="https://arxiv.org/abs/2404.10179v2">Scaling Instructable Agents Across Many Simulated Worlds</a>, SIMA Team et al., arXiv preprint arXiv:2404.10179</p>
<p>[March, 2024] <a href="https://github.com/OpenGenerativeAI/llm-colosseum">Evaluate LLMs in real time with Street Fighter III</a>, OpenGenerativeAI team et al., n/a</p>
<p>[December, 2023] <a href="https://arxiv.org/abs/2312.11865">Large language models play starcraft ii: Benchmarks and a chain of summarization approach</a>, Weiyu Ma et al., arXiv preprint arXiv:2312.11865</p>
<p>[October, 2023] <a href="https://arxiv.org/abs/2310.17512">CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents</a>, Qinlin Zhao et al., arXiv</p>
<p>[September, 2020] <a href="https://doi.org/10.1145/3406499.3418760">SEAN: Social Environment for Autonomous Navigation</a>, Nathan Tsoi et al., Proceedings of the 8th International Conference on Human-Agent Interaction</p>
<h3 id="environmentsvirtual">environments/virtual<a class="headerlink" href="#environmentsvirtual" title="Permanent link"></a></h3>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.07939">UFO: A UI-Focused Agent for Windows OS Interaction</a>, Chaoyun Zhang et al., arXiv preprint arXiv:2402.07939</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.07456">Os-copilot: Towards generalist computer agents with self-improvement</a>, Zhiyong Wu et al., arXiv preprint arXiv:2402.07456</p>
<p>[January, 2024] <a href="https://arxiv.org/abs/2401.16158">Mobile-Agent: Autonomous multi-modal mobile device agent with visual perception</a>, Junyang Wang et al., arXiv preprint arXiv:2401.16158</p>
<p>[January, 2024] <a href="https://arxiv.org/abs/2401.13649">Visualwebarena: Evaluating multimodal agents on realistic visual web tasks</a>, Jing Yu Koh et al., arXiv preprint arXiv:2401.13649</p>
<p>[January, 2024] <a href="https://arxiv.org/abs/2306.06070">Mind2web: Towards a generalist agent for the web</a>, Xiang Deng et al., Advances in Neural Information Processing Systems</p>
<p>[December, 2023] <a href="https://arxiv.org/abs/2312.13771">Appagent: Multimodal agents as smartphone users</a>, Zhao Yang et al., arXiv preprint arXiv:2312.13771</p>
<p>[July, 2023] <a href="https://arxiv.org/abs/2307.13854">Webarena: A realistic web environment for building autonomous agents</a>, Shuyan Zhou et al., arXiv preprint arXiv:2307.13854</p>
<p>[July, 2023] <a href="https://arxiv.org/abs/2307.10088">Android in the wild: A large-scale dataset for android device control</a>, Christopher Rawles et al., arXiv preprint arXiv:2307.10088</p>
<p>[December, 2022] <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf">Webshop: Towards scalable real-world web interaction with grounded language agents</a>, Shunyu Yao et al., Advances in Neural Information Processing Systems</p>
<p>[July, 2022] <a href="https://arxiv.org/abs/2202.08137">A data-driven approach for learning to control computers</a>, Peter C Humphreys et al., International Conference on Machine Learning</p>
<p>[February, 2022] <a href="https://arxiv.org/abs/2202.02312">A dataset for interactive vision-language navigation with unknown command feasibility</a>, Andrea Burns et al., European Conference on Computer Vision</p>
<p>[May, 2021] <a href="https://arxiv.org/abs/2105.13231">Androidenv: A reinforcement learning platform for android</a>, Daniel Toyama et al., arXiv preprint arXiv:2105.13231</p>
<p>[March, 2021] <a href="https://arxiv.org/abs/2103.16057">Grounding open-domain instructions to automate web support tasks</a>, Nancy Xu et al., arXiv preprint arXiv:2103.16057</p>
<p>[September, 2020] <a href="https://arxiv.org/abs/1909.00031">Interactive task learning from GUI-grounded natural language instructions and demonstrations</a>, Toby Jia-Jun Li et al., Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</p>
<p>[May, 2020] <a href="https://arxiv.org/abs/2005.03776">Mapping natural language instructions to mobile UI action sequences</a>, Yang Li et al., arXiv preprint arXiv:2005.03776</p>
<p>[March, 2019] <a href="https://dl.acm.org/doi/10.1145/3332165.3347899">Pumice: A multi-modal agent that learns concepts and conditionals from natural language and demonstrations</a>, Toby Jia-Jun Li et al., Proceedings of the 32nd annual ACM symposium on user interface software and technology</p>
<p>[March, 2018] <a href="https://ieeexplore.ieee.org/document/8506506">Appinite: A multi-modal interface for specifying data descriptions in programming by demonstration using natural language instructions</a>, Toby Jia-Jun Li et al., 2018 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)</p>
<p>[February, 2018] <a href="https://arxiv.org/abs/1802.08802">Reinforcement learning on web interfaces using workflow-guided exploration</a>, Evan Zheran Liu et al., arXiv preprint arXiv:1802.08802</p>
<p>[August, 2017] <a href="https://proceedings.mlr.press/v70/shi17a/shi17a.pdf">World of bits: An open-domain platform for web-based agents</a>, Tianlin Shi et al., International Conference on Machine Learning</p>
<p>[August, 2009] <a href="https://aclanthology.org/P09-1010/">Reinforcement learning for mapping instructions to actions</a>, Satchuthananthavale RK Branavan et al., Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</p>
<p>[July, 2007] <a href="https://cdn.aaai.org/AAAI/2007/AAAI07-240.pdf">Plow: A collaborative task learning agent</a>, James Allen et al., AAAI</p>
<h3 id="environmentsrobotics">environments/robotics<a class="headerlink" href="#environmentsrobotics" title="Permanent link"></a></h3>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.12910">Yell At Your Robot: Improving On-the-Fly from Language Corrections</a>, Lucy Xiaoyang Shi et al., arXiv</p>
<p>[December, 2023] <a href="https://proceedings.mlr.press/v205/xiong23a.html">RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments</a>, Haoyu Xiong et al., Proceedings of The 6th Conference on Robot Learning</p>
<p>[August, 2023] <a href="https://arxiv.org/abs/2108.06038">Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration</a>, Chen Wang et al., arXiv</p>
<p>[July, 2023] <a href="https://arxiv.org/abs/2307.15363">Robotic vision for human-robot interaction and collaboration: A survey and systematic review</a>, Nicole Robinson et al., ACM Transactions on Human-Robot Interaction</p>
<p>[June, 2023] <a href="https://arxiv.org/abs/2306.12372">One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments</a>, Yufei Wang et al., Robotics: Science and Systems (RSS)</p>
<p>[April, 2023] <a href="https://doi.org/10.1145/3571718">15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction</a>, Katie Winkle et al., J. Hum.-Robot Interact.</p>
<p>[March, 2023] <a href="https://doi.org/10.1145/3570169">Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective</a>, Jacqueline Urakami et al., J. Hum.-Robot Interact.</p>
<p>[October, 2022] <a href="https://arxiv.org/abs/2212.05286">A survey of multi-agent Human--Robot Interaction systems</a>, Abhinav Dahiya et al., Robotics and Autonomous Systems</p>
<p>[August, 2022] <a href="https://say-can.github.io/">Do As I Can and Not As I Say: Grounding Language in Robotic Affordances</a>, Michael Ahn et al., arXiv preprint arXiv:2204.01691</p>
<p>[June, 2022] <a href="https://arxiv.org/abs/2207.05608">Inner Monologue: Embodied Reasoning through Planning with Language Models</a>, Wenlong Huang et al., arXiv preprint arXiv:2207.05608</p>
<p>[June, 2021] <a href="https://link.springer.com/article/10.1007/s12369-020-00666-5">A taxonomy to structure and analyze human--robot interaction</a>, Linda Onnasch et al., International Journal of Social Robotics</p>
<p>[April, 2016] <a href="https://journals.sagepub.com/doi/10.1177/0018720816644364">Human--robot interaction: status and challenges</a>, Thomas B Sheridan et al., Human factors</p>
<h3 id="modelingin-context-learning">modeling/in-context-learning<a class="headerlink" href="#modelingin-context-learning" title="Permanent link"></a></h3>
<p>[September, 2024] <a href="https://arxiv.org/abs/2309.08172">LASER: LLM Agent with State-Space Exploration for Web Navigation</a>, Kaixin Ma et al., arXiv</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.08978">AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents</a>, Yao Fu et al., arXiv preprint arXiv:2403.08978</p>
<p>[January, 2024] <a href="https://openreview.net/forum?id=Pc8AU1aF5e">Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control</a>, Longtao Zheng et al., The Twelfth International Conference on Learning Representations</p>
<p>[November, 2023] <a href="https://openreview.net/forum?id=rnKgbKmelt">AdaPlanner: Adaptive Planning from Feedback with Language Models</a>, Haotian Sun et al., Thirty-seventh Conference on Neural Information Processing Systems</p>
<p>[May, 2023] <a href="https://arxiv.org/abs/2305.16291">Voyager: An Open-Ended Embodied Agent with Large Language Models</a>, Guanzhi Wang et al., arXiv</p>
<p>[May, 2023] <a href="https://arxiv.org/abs/2305.14257">Hierarchical Prompting Assists Large Language Model on Web Navigation</a>, Abishek Sridhar et al., arXiv</p>
<p>[May, 2023] <a href="https://arxiv.org/abs/2305.15486">SPRING: Studying the Paper and Reasoning to Play Games</a>, Yue Wu et al., arXiv</p>
<p>[March, 2023] <a href="https://arxiv.org/abs/2303.17491">Language Models can Solve Computer Tasks</a>, Geunwoo Kim et al., arXiv</p>
<p>[March, 2023] <a href="https://arxiv.org/abs/2303.17071">DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents</a>, Varun Nair et al., arXiv</p>
<h3 id="modelingfinetuning">modeling/finetuning<a class="headerlink" href="#modelingfinetuning" title="Permanent link"></a></h3>
<p>[August, 2024] <a href="https://arxiv.org/abs/2308.07241">Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents</a>, Byeonghwi Kim et al., arXiv</p>
<p>[April, 2024] <a href="https://arxiv.org/abs/2404.03648">AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent</a>, Hanyu Lai et al., arXiv preprint arXiv:2404.03648</p>
<p>[April, 2024] <a href="https://arxiv.org/abs/2404.11246">Learning Social Navigation from Demonstrations with Deep Neural Networks</a>, Yigit Yildirim et al., arXiv</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.02502">Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents</a>, Yifan Song et al., arXiv preprint arXiv:2403.02502</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.12881">Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models</a>, Zehui Chen et al., arXiv preprint arXiv:2403.12881</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.04476">Dual-View Visual Contextualization for Web Navigation</a>, Jihyung Kil et al., arXiv</p>
<p>[January, 2024] <a href="https://openreview.net/forum?id=9JQtrumvg8">A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis</a>, Izzeddin Gur et al., The Twelfth International Conference on Learning Representations</p>
<p>[January, 2024] <a href="https://arxiv.org/abs/2401.01614">GPT-4V(ision) is a Generalist Web Agent, if Grounded</a>, Boyuan Zheng et al., arXiv</p>
<p>[November, 2023] <a href="https://openreview.net/forum?id=3PjCt4kmRx">From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces</a>, Peter Shaw et al., Thirty-seventh Conference on Neural Information Processing Systems</p>
<p>[October, 2023] <a href="https://arxiv.org/abs/2210.03945">Understanding HTML with Large Language Models</a>, Izzeddin Gur et al., arXiv</p>
<p>[October, 2023] <a href="https://arxiv.org/abs/2210.03629">ReAct: Synergizing Reasoning and Acting in Language Models</a>, Shunyu Yao et al., arXiv</p>
<p>[October, 2023] <a href="https://arxiv.org/abs/2310.03779">HandMeThat: Human-Robot Communication in Physical and Social Environments</a>, Yanming Wan et al., arXiv</p>
<p>[May, 2023] <a href="https://openreview.net/forum?id=oLc9sGOBbc">Instruction-Finetuned Foundation Models for Multimodal Web Navigation</a>, Hiroki Furuta et al., ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models</p>
<p>[March, 2023] <a href="https://link.springer.com/article/10.1007/s11633-022-1383-7">Offline pre-trained multi-agent decision transformer</a>, Linghui Meng et al., Machine Intelligence Research</p>
<p>[October, 2022] <a href="https://www.cs.utexas.edu/~xiao/SCAND/SCAND.html">Socially CompliAnt Navigation Dataset (SCAND): A Large-Scale Dataset Of Demonstrations For Social Navigation</a>, Haresh Karnan et al., IEEE Robotics and Automation Letters</p>
<p>[October, 2022] <a href="https://arxiv.org/abs/2210.12485">DANLI: Deliberative Agent for Following Natural Language Instructions</a>, Yichi Zhang et al., arXiv</p>
<p>[July, 2022] <a href="https://ieeexplore.ieee.org/abstract/document/9837390/citations#citations">Dialfred: Dialogue-enabled agents for embodied instruction following</a>, Xiaofeng Gao et al., IEEE Robotics and Automation Letters</p>
<p>[May, 2021] <a href="https://ieeexplore.ieee.org/document/9561973">Learning World Transition Model for Socially Aware Robot Navigation</a>, Yuxiang Cui et al., 2021 IEEE International Conference on Robotics and Automation (ICRA)</p>
<p>[December, 2018] <a href="https://proceedings.neurips.cc/paper/2018/hash/240c945bb72980130446fc2b40fbb8e0-Abstract.html">Multi-agent generative adversarial imitation learning</a>, Jiaming Song et al., Advances in neural information processing systems</p>
<p>[March, 2018] <a href="https://arxiv.org/abs/1803.07612">Generative multi-agent behavioral cloning</a>, Eric Zhan et al., arXiv preprint arXiv:1803.07612</p>
<h3 id="modelingreinforcement-learning">modeling/reinforcement-learning<a class="headerlink" href="#modelingreinforcement-learning" title="Permanent link"></a></h3>
<p>[April, 2024] <a href="https://arxiv.org/abs/2404.06474v2">Autonomous Evaluation and Refinement of Digital Agents</a>, Jiayi Pan et al., arXiv preprint arXiv:2404.06474</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.08715">SOTOPIA-$\pi$: Interactive Learning of Socially Intelligent Language Agents</a>, Ruiyi Wang et al., arXiv</p>
<p>[March, 2024] <a href="https://doi.org/10.1038/s41467-024-45965-x">TacticAI: an AI assistant for football tactics</a>, Zhe Wang et al., Nature Communications</p>
<p>[March, 2023] <a href="https://arxiv.org/abs/2303.01502">Computational Language Acquisition with Theory of Mind</a>, Andy Liu et al., arXiv</p>
<p>[July, 2022] <a href="https://escholarship.org/uc/item/7p65n371">Language Learning from Communicative Goals and Linguistic Input</a>, Hao Zhu et al., Proceedings of the Annual Meeting of the Cognitive Science Society</p>
<p>[April, 2022] <a href="https://academic.oup.com/jole/article/7/2/213/7128304">Language games meet multi-agent reinforcement learning: A case study for the naming game</a>, Paul Van Eecke et al., Journal of Language Evolution</p>
<p>[November, 2019] <a href="https://aclanthology.org/D19-3010">{EGG}: a toolkit for research on Emergence of lan{G}uage in Games</a>, Kharitonov et al., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</p>
<p>[October, 2018] <a href="https://doi.org/10.1145/3269206.3272021">Real-Time Bidding with Multi-Agent Reinforcement Learning in Display Advertising</a>, Junqi Jin et al., Proceedings of the 27th ACM International Conference on Information and Knowledge Management</p>
<p>[February, 2018] <a href="https://openreview.net/forum?id=Hk6WhagRW">Emergent Communication through Negotiation</a>, Kris Cao et al., International Conference on Learning Representations</p>
<p>[April, 2017] <a href="https://www.nature.com/articles/nature24270">Mastering the game of go without human knowledge</a>, David Silver et al., nature</p>
<p>[January, 2016] <a href="https://www.nature.com/articles/nature16961">Mastering the game of Go with deep neural networks and tree search</a>, David Silver et al., nature</p>
<p>[July, 2010] <a href="https://www.aclweb.org/anthology/P10-1129">Reading between the lines: Learning to map high-level instructions to commands</a>, SRK Branavan et al., Proceedings of the 48th annual meeting of the association for computational linguistics</p>
<h3 id="evaluationlanguage">evaluation/language<a class="headerlink" href="#evaluationlanguage" title="Permanent link"></a></h3>
<p>[October, 2024] <a href="https://openreview.net/forum?id=mM7VurbA4r">SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents</a>, Xuhui Zhou et al., ICLR</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.13679">RoleInteract: Evaluating the Social Interaction of Role-Playing Agents</a>, Hongzhan Chen et al., arXiv</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.11807">How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments</a>, Jen-tse Huang et al., arXiv</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.11958">Automatic Evaluation for Mental Health Counseling using LLMs</a>, Anqi Li et al., arXiv</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.05863">How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis</a>, Federico Bianchi et al., arXiv</p>
<p>[February, 2024] <a href="https://api.semanticscholar.org/CorpusID:267523076">Can Large Language Model Agents Simulate Human Trust Behaviors?</a>, Chengxing Xie et al., ArXiv</p>
<p>[January, 2024] <a href="https://api.semanticscholar.org/CorpusID:266725580">LLM Harmony: Multi-Agent Communication for Problem Solving</a>, Sumedh Rasal et al., ArXiv</p>
<p>[December, 2023] <a href="https://aclanthology.org/2023.findings-emnlp.371">x{D}ial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark</a>, Zhang et al., Findings of the Association for Computational Linguistics: EMNLP 2023</p>
<p>[December, 2023] <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/a3621ee907def47c1b952ade25c67698-Paper-Conference.pdf">CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society</a>, Guohao Li et al., Advances in Neural Information Processing Systems</p>
<p>[October, 2023] <a href="https://arxiv.org/pdf/2310.14985.pdf">Llm-based agent society investigation: Collaboration and confrontation in avalon gameplay</a>, Yihuai Lan et al., arXiv preprint arXiv:2310.14985</p>
<p>[October, 2023] <a href="https://arxiv.org/abs/2310.09233">AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems</a>, Junjie Zhang et al., arXiv</p>
<p>[September, 2023] <a href="https://aclanthology.org/2023.sigdial-1.25">Approximating Online Human Evaluation of Social Chatbots with Prompting</a>, Svikhnushina et al., Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p>
<p>[August, 2023] <a href="https://arxiv.org/abs/2308.10278">CharacterChat: Learning towards Conversational AI with Personalized Social Support</a>, Quan Tu et al., arXiv</p>
<p>[August, 2023] <a href="https://arxiv.org/abs/2308.07201">ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate</a>, Chi-Min Chan et al., arXiv</p>
<p>[July, 2023] <a href="https://aclanthology.org/2023.acl-long.839">Don{'}t Forget Your {ABC}{'}s: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems</a>, Finch et al., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</p>
<p>[May, 2023] <a href="https://api.semanticscholar.org/CorpusID:268032940">PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits</a>, Hang Jiang et al., NAACL Findings</p>
<p>[May, 2023] <a href="https://arxiv.org/abs/2305.14757">Psychological Metrics for Dialog System Evaluation</a>, Salvatore Giorgi et al., arXiv</p>
<p>[May, 2023] <a href="https://arxiv.org/pdf/2305.07797">ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems</a>, Sarik Ghazarian et al., arXiv</p>
<p>[May, 2022] <a href="https://aclanthology.org/2022.nlp4convai-1.8">Human Evaluation of Conversations is an Open Problem: comparing the sensitivity of various methods for evaluating dialogue agents</a>, Smith et al., Proceedings of the 4th Workshop on NLP for Conversational AI</p>
<p>[November, 2021] <a href="https://aclanthology.org/2021.eancs-1.3">A Comprehensive Assessment of Dialog Evaluation Metrics</a>, Yeh et al., The First Workshop on Evaluations and Assessments of Neural Conversation Systems</p>
<p>[August, 2021] <a href="https://aclanthology.org/2021.acl-long.441">{D}yna{E}val: Unifying Turn and Dialogue Level Evaluation</a>, Zhang et al., Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</p>
<p>[January, 2021] <a href="https://link.springer.com/article/10.1007/s10462-020-09866-x">Survey on evaluation methods for dialogue systems</a>, Jan Deriu et al., Artificial Intelligence Review</p>
<p>[November, 2020] <a href="https://aclanthology.org/2020.emnlp-main.742">{GRADE}: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems</a>, Huang et al., Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</p>
<p>[July, 2020] <a href="https://aclanthology.org/2020.sigdial-1.29">Towards Unified Dialogue System Evaluation: A Comprehensive Analysis of Current Evaluation Protocols</a>, Finch et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p>
<p>[July, 2020] <a href="https://aclanthology.org/2020.acl-srw.27">u{BLEU}: Uncertainty-Aware Automatic Evaluation Method for Open-Domain Dialogue Systems</a>, Tsuta et al., Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</p>
<p>[July, 2020] <a href="https://aclanthology.org/2020.sigdial-1.8">{C}onvo{K}it: A Toolkit for the Analysis of Conversations</a>, Chang et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p>
<p>[July, 2020] <a href="https://aclanthology.org/2020.sigdial-1.28">Unsupervised Evaluation of Interactive Dialog with {D}ialo{GPT}</a>, Mehri et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p>
<h3 id="evaluationembodied">evaluation/embodied<a class="headerlink" href="#evaluationembodied" title="Permanent link"></a></h3>
<p>[December, 2024] <a href="https://arxiv.org/abs/2312.08463">How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning</a>, Siddarth Singh et al., arXiv</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.12482">Embodied LLM Agents Learn to Cooperate in Organized Teams</a>, Xudong Guo et al., arXiv</p>
<p>[December, 2022] <a href="https://aclanthology.org/2022.emnlp-main.635">Don{'}t Copy the Teacher: Data and Model Challenges in Embodied Dialogue</a>, Min et al., Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</p>
<p>[September, 2022] <a href="https://aclanthology.org/2022.sigdial-1.13">{Dialog Acts for Task-Driven Embodied Agents}</a>, Spandana Gella et al., Proceedings of the 23nd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDial)</p>
<p>[June, 2022] <a href="https://aclanthology.org/2022.lrec-1.431">Analysis of Dialogue in Human-Human Collaboration in {M}inecraft</a>, Ichikawa et al., Proceedings of the Thirteenth Language Resources and Evaluation Conference</p>
<p>[February, 2022] <a href="https://doi.org/10.1145/3476413">SocNavBench: A Grounded Simulation Testing Framework for Evaluating Social Navigation</a>, Abhijat Biswas et al., J. Hum.-Robot Interact.</p>
<p>[February, 2022] <a href="https://arxiv.org/abs/2110.00534">{TEACh: Task-driven Embodied Agents that Chat}</a>, Aishwarya Padmakumar et al., Proceedings of the AAAI Conference on Artificial Intelligence</p>
<p>[November, 2021] <a href="https://aclanthology.org/2021.emnlp-main.85">{M}ind{C}raft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks</a>, Bara et al., Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</p>
<p>[July, 2021] <a href="https://proceedings.mlr.press/v139/leibo21a.html">Scalable evaluation of multi-agent reinforcement learning with melting pot</a>, Joel Z Leibo et al., International conference on machine learning</p>
<p>[January, 2021] <a href="https://dl.acm.org/doi/abs/10.5555/3463952.3464159">Evaluating the Robustness of Collaborative Agents</a>, Paul Knott et al., Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems</p>
<p>[November, 2020] <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500460.pdf">A Cordial Sync: Going Beyond Marginal Policies For Multi-Agent Embodied Tasks</a>, Unnat Jain et al., ECCV</p>
<p>[July, 2019] <a href="https://aclanthology.org/P19-1537">Collaborative Dialogue in {M}inecraft</a>, Narayan-Chen et al., Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</p>
<p>[June, 2019] <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Jain_Two_Body_Problem_Collaborative_Visual_Task_Completion_CVPR_2019_paper.pdf">Two Body Problem: Collaborative Visual Task Completion</a>, Unnat Jain et al., CVPR</p>
<p>[May, 2016] <a href="https://dl.acm.org/doi/pdf/10.1145/2851581.2892305">Evaluation of starcraft artificial intelligence competition bots by experienced human players</a>, Man-Je Kim et al., Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems</p>
<h3 id="evaluationvirtual">evaluation/virtual<a class="headerlink" href="#evaluationvirtual" title="Permanent link"></a></h3>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.05930">WebLINX: Real-World Website Navigation with Multi-Turn Dialogue</a>, Xing Han Lù et al., ArXiv</p>
<p>[November, 2023] <a href="https://arxiv.org/abs/2311.12983">GAIA: a benchmark for General AI Assistants</a>, Grégoire Mialon et al., arXiv</p>
<p>[November, 2023] <a href="https://api.semanticscholar.org/CorpusID:265301950">MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</a>, Sirui Hong et al., ArXiv</p>
<p>[October, 2023] <a href="https://api.semanticscholar.org/CorpusID:264172893">OpenAgents: An Open Platform for Language Agents in the Wild</a>, Tianbao Xie et al., ArXiv</p>
<p>[September, 2023] <a href="https://api.semanticscholar.org/CorpusID:261556862">Cognitive Architectures for Language Agents</a>, Theodore R. Sumers et al., ArXiv</p>
<p>[February, 2020] <a href="https://doi.org/10.1145/3374920.3374956">Embedding Conversational Agents into AR: Invisible or with a Realistic Human Body?</a>, Jens Reinhardt et al., Proceedings of the Fourteenth International Conference on Tangible, Embedded, and Embodied Interaction</p>
<p>[May, 2019] <a href="https://doi.org/10.1145/3290605.3300511">Exploring Virtual Agents for Augmented Reality</a>, Isaac Wang et al., CHI</p>
<h3 id="evaluationrobotics">evaluation/robotics<a class="headerlink" href="#evaluationrobotics" title="Permanent link"></a></h3>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.10506">HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation</a>, Carmelo Sferrazza et al., arXiv</p>
<p>[December, 2020] <a href="https://doi.org/10.1080/01691864.2019.1698462">Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition</a>, Y. Mizuchi et al., Advanced Robotics</p>
<p>[July, 2020] <a href="https://www.sciencedirect.com/science/article/pii/S0925753520300643">Safety bounds in human robot interaction: A survey</a>, Angeliki Zacharaki et al., Safety science</p>
<p>[December, 2015] <a href="https://www.sciencedirect.com/science/article/pii/S0004370215001174">RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots</a>, Luca Iocchi et al., Artificial Intelligence</p>
<p>[October, 2011] <a href="https://journals.sagepub.com/doi/10.1177/0018720811417254">A meta-analysis of factors affecting trust in human-robot interaction</a>, Peter A Hancock et al., Human factors</p>
<p>[November, 2009] <a href="https://link.springer.com/article/10.1007/s12369-008-0001-3">Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots</a>, Christoph Bartneck et al., International journal of social robotics</p>
<p>[March, 2006] <a href="https://doi.org/10.1145/1121241.1121249">Common metrics for human-robot interaction</a>, Aaron Steinfeld et al., Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction</p>
<p>[January, 2003] <a href="https://ieeexplore.ieee.org/document/1174284">Theory and evaluation of human robot interactions</a>, J. Scholtz et al., 36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the</p>
<h3 id="interactionstext">interactions/text<a class="headerlink" href="#interactionstext" title="Permanent link"></a></h3>
<p>[May, 2024] <a href="https://arxiv.org/pdf/2403.03297.pdf">" It's the only thing I can trust": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance</a>, JiWoong Jang et al., arXiv preprint arXiv:2403.03297</p>
<p>[March, 2024] <a href="https://dl.acm.org/doi/pdf/10.1145/3640543.3645213">AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy</a>, Daniel Pillis et al., Proceedings of the 29th International Conference on Intelligent User Interfaces</p>
<p>[March, 2024] <a href="https://dl.acm.org/doi/pdf/10.1145/3640543.3645198">Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration</a>, Crystal Qian et al., Proceedings of the 29th International Conference on Intelligent User Interfaces</p>
<p>[May, 2023] <a href="https://arxiv.org/pdf/2308.10385.pdf">The Effects of Engaging and Affective Behaviors of Virtual Agents in Group Decision-Making</a>, Hanseob Kim et al., Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</p>
<p>[April, 2023] <a href="https://dl.acm.org/doi/pdf/10.1145/3544548.3580995">Collaborating with a Text-Based Chatbot: An Exploration of Real-World Collaboration Strategies Enacted during Human-Chatbot Interactions</a>, Amon Rapp et al., Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</p>
<p>[April, 2023] <a href="https://dl.acm.org/doi/pdf/10.1145/3544548.3581384">Exploring effects of chatbot-based social contact on reducing mental illness stigma</a>, Yi-Chieh Lee et al., Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</p>
<p>[September, 2022] <a href="https://www.mdpi.com/2227-9709/9/4/81">Interacting with a chatbot-based advising system: Understanding the effect of chatbot personality and user gender on behavior</a>, Mohammad Amin Kuhail et al., Informatics</p>
<p>[April, 2022] <a href="https://dl.acm.org/doi/pdf/10.1145/3491102.3502058">User perceptions of extraversion in chatbots after repeated use</a>, Sarah Theres V{\"o}lkel et al., Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</p>
<h3 id="interactionsembodied">interactions/embodied<a class="headerlink" href="#interactionsembodied" title="Permanent link"></a></h3>
<p>[December, 2023] <a href="https://arxiv.org/abs/2312.15224">Llm-powered hierarchical language agent for real-time human-ai coordination</a>, Jijia Liu et al., arXiv preprint arXiv:2312.15224</p>
<p>[December, 2023] <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/4818263715b25dc137d393af8af6d2fc-Paper-Conference.pdf">Diverse Conventions for Human-AI Collaboration</a>, Bidipta Sarkar et al., Advances in Neural Information Processing Systems</p>
<p>[May, 2023] <a href="https://proceedings.mlr.press/v202/szot23a/szot23a.pdf">Adaptive coordination in social embodied rearrangement</a>, Andrew Szot et al., International Conference on Machine Learning</p>
<p>[April, 2023] <a href="https://dl.acm.org/doi/abs/10.1145/3586183.3606763">Generative agents: Interactive simulacra of human behavior</a>, Joon Sung Park et al., Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</p>
<p>[January, 2023] <a href="https://ieeexplore.ieee.org/document/10161352">Nopa: Neurally-guided online probabilistic assistance for building socially intelligent home assistants</a>, Xavier Puig et al., 2023 IEEE International Conference on Robotics and Automation (ICRA)</p>
<p>[May, 2021] <a href="https://escholarship.org/uc/item/9ks6n70q">Interaction flexibility in artificial agents teaming with humans</a>, Patrick Nalepka et al., Proceedings of the Annual Meeting of the Cognitive Science Society</p>
<p>[January, 2021] <a href="https://openreview.net/forum?id=w_7JMpGZRh0">Watch-And-Help: A Challenge for Social Perception and Human-{{}AI{}} Collaboration</a>, Xavier Puig et al., International Conference on Learning Representations</p>
<p>[October, 2019] <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf">On the utility of learning about humans for human-ai coordination</a>, Micah Carroll et al., Advances in neural information processing systems</p>
<h3 id="interactionsrobot">interactions/robot<a class="headerlink" href="#interactionsrobot" title="Permanent link"></a></h3>
<p>[March, 2024] <a href="https://arxiv.org/abs/2401.14673">Generative expressive robot behaviors using large language models</a>, Karthik Mahadevan et al., Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction</p>
<p>[October, 2023] <a href="https://arxiv.org/abs/2310.12931">Eureka: Human-level reward design via coding large language models</a>, Yecheng Jason Ma et al., arXiv preprint arXiv:2310.12931</p>
<p>[August, 2023] <a href="https://arxiv.org/abs/2309.02721">Gesture-informed robot assistance via foundation models</a>, Li-Heng Lin et al., 7th Annual Conference on Robot Learning</p>
<p>[July, 2023] <a href="https://arxiv.org/abs/2307.15217">Open problems and fundamental limitations of reinforcement learning from human feedback</a>, Stephen Casper et al., arXiv preprint arXiv:2307.15217</p>
<p>[July, 2023] <a href="https://arxiv.org/abs/2307.01928">Robots that ask for help: Uncertainty alignment for large language model planners</a>, Allen Z Ren et al., arXiv preprint arXiv:2307.01928</p>
<p>[June, 2023] <a href="https://arxiv.org/abs/2306.08647">Language to rewards for robotic skill synthesis</a>, Wenhao Yu et al., arXiv preprint arXiv:2306.08647</p>
<p>[March, 2023] <a href="https://arxiv.org/abs/2301.02555">No, to the right: Online language corrections for robotic manipulation via shared autonomy</a>, Yuchen Cui et al., Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction</p>
<p>[March, 2023] <a href="https://arxiv.org/abs/2211.12705">In-Mouth Robotic Bite Transfer with Visual and Haptic Sensing</a>, Lorenzo Shaikewitz et al., International Conference on Robotics and Automation (ICRA)</p>
<p>[March, 2023] <a href="https://arxiv.org/abs/2212.03363">Few-shot preference learning for human-in-the-loop rl</a>, Donald Joseph Hejna III et al., Conference on Robot Learning</p>
<p>[August, 2021] <a href="https://arxiv.org/abs/2006.16732">Formalizing and guaranteeing human-robot interaction</a>, Hadas Kress-Gazit et al., Communications of the ACM</p>
<h3 id="interactionshuman">interactions/human<a class="headerlink" href="#interactionshuman" title="Permanent link"></a></h3>
<p>[April, 2024] <a href="https://www.negotiage.com/">NegotiAge</a>, Lee Lindquist et al., NegotiAge</p>
<p>[September, 2023] <a href="https://arxiv.org/pdf/2309.12309.pdf">Rehearsal: Simulating conflict to teach conflict resolution</a>, Omar Shaikh et al., arXiv preprint arXiv:2309.12309</p>
<p>[June, 2022] <a href="https://ego4d-data.org/">Ego4D: Around the {W}orld in 3,000 {H}ours of {E}gocentric {V}ideo</a>, Kristen Grauman et al., IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</p>
<p>[December, 2021] <a href="https://link.springer.com/referenceworkentry/10.1007/978-3-030-49629-6_26">Agent reasoning in AI-powered negotiation</a>, Tinglong Dai et al., Handbook of Group Decision and Negotiation</p>
<p>[December, 2021] <a href="https://link.springer.com/referenceworkentry/10.1007/978-3-030-49629-6_38">Negotiation, Online Dispute Resolution, and Artificial Intelligence</a>, John Zeleznikow et al., Handbook of Group Decision and Negotiation</p>
<p>[October, 2021] <a href="https://journals.sagepub.com/doi/full/10.1177/0022242920956676">Artificial intelligence coaches for sales agents: Caveats and solutions</a>, Xueming Luo et al., Journal of Marketing</p>
<p>[May, 2021] <a href="https://ieeexplore.ieee.org/document/9475925">Towards an AI Coach to Infer Team Mental Model Alignment in Healthcare</a>, Sangwon Seo et al., 2021 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)</p>
<p>[October, 2020] <a href="https://humanfactors.jmir.org/2020/1/e16762">A chatbot-based coaching intervention for adolescents to promote life skills: pilot study</a>, Silvia Gabrielli et al., JMIR human factors</p>
<p>[November, 2019] <a href="https://www.sciencedirect.com/science/article/pii/S1077314219301158">Analyzing human–human interactions: A survey</a>, Alexandros Stergiou et al., Computer Vision and Image Understanding</p>
<p>[December, 2018] <a href="https://dl.acm.org/doi/abs/10.1145/3271484">Blending human and artificial intelligence to support autistic children’s social communication skills</a>, Ka{\'s}ka Porayska-Pomsta et al., ACM Transactions on Computer-Human Interaction (TOCHI)</p>
<h3 id="applicationshealth">applications/health<a class="headerlink" href="#applicationshealth" title="Permanent link"></a></h3>
<p>[October, 2024] <a href="https://arxiv.org/abs/2310.02374">Conversational Health Agents: A Personalized LLM-Powered Agent Framework</a>, Mahyar Abbasian et al., arXiv</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.13313">Polaris: A Safety-focused LLM Constellation Architecture for Healthcare</a>, Subhabrata Mukherjee et al., arXiv</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.05547">Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset</a>, Hengguan Huang et al., arXiv</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.09742">AI Hospital: Interactive Evaluation and Collaboration of LLMs as Intern Doctors for Clinical Diagnosis</a>, Zhihao Fan et al., arXiv</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.17546">COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt</a>, Suyeon Lee et al., arXiv</p>
<p>[January, 2024] <a href="https://arxiv.org/abs/2401.14589">Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias</a>, Yu He Ke et al., arXiv</p>
<p>[May, 2023] <a href="https://arxiv.org/abs/2305.08982">Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback</a>, Shang-Ling Hsu et al., arXiv</p>
<p>[May, 2023] <a href="https://arxiv.org/abs/2305.05138">Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media</a>, Wei Qin et al., arXiv</p>
<p>[May, 2023] <a href="https://pubmed.ncbi.nlm.nih.gov/37152238/">An artificial intelligence-based chatbot for prostate cancer education: Design and patient evaluation study</a>, Magdalena Görtz et al., Digital Health</p>
<h3 id="applicationspolicy">applications/policy<a class="headerlink" href="#applicationspolicy" title="Permanent link"></a></h3>
<p>[November, 2024] <a href="https://arxiv.org/abs/2311.04076">Do LLMs exhibit human-like response biases? A case study in survey design</a>, Lindia Tjuatja et al., arXiv</p>
<p>[March, 2024] <a href="https://arxiv.org/abs/2403.09498">From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News</a>, Yuhan Liu et al., arXiv</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.01908">Large language models cannot replace human participants because they cannot portray identity groups</a>, Angelina Wang et al., arXiv</p>
<p>[February, 2024] <a href="https://arxiv.org/abs/2402.16333">Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation</a>, Xinyi Mou et al., arXiv</p>
<p>[August, 2022] <a href="https://doi.org/10.1145/3526113.3545616">Social Simulacra: Creating Populated Prototypes for Social Computing Systems</a>, Joon Sung Park et al., Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology</p>
<h3 id="concernsrisks">concerns/risks<a class="headerlink" href="#concernsrisks" title="Permanent link"></a></h3>
<p>[February, 2024] <a href="https://www.nature.com/articles/s41598-024-53755-0">The potential of generative AI for personalized persuasion at scale</a>, SC Matz et al., Scientific Reports</p>
<p>[February, 2024] <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/fd6613131889a4b656206c50a8bd7790-Paper-Conference.pdf">Jailbroken: How does llm safety training fail?</a>, Alexander Wei et al., Advances in Neural Information Processing Systems</p>
<p>[January, 2024] <a href="https://arxiv.org/abs/2401.07836">Two Types of AI Existential Risk: Decisive and Accumulative</a>, Atoosa Kasirzadeh et al., arXiv</p>
<p>[December, 2023] <a href="https://arxiv.org/abs/2312.06674">Llama guard: Llm-based input-output safeguard for human-ai conversations</a>, Hakan Inan et al., arXiv preprint arXiv:2312.06674</p>
<p>[September, 2023] <a href="https://arxiv.org/abs/2309.07864">The rise and potential of large language model based agents: A survey</a>, Zhiheng Xi et al., arXiv preprint arXiv:2309.07864</p>
<p>[July, 2023] <a href="https://dl.acm.org/doi/fullHtml/10.1145/3604632">Voice in the machine: Ethical considerations for language-capable robots</a>, Tom Williams et al., Communications of the ACM</p>
<p>[March, 2023] <a href="https://arxiv.org/abs/2303.08721">Artificial Influence: An Analysis Of AI-Driven Persuasion</a>, Matthew Burtell et al., arXiv</p>
<p>[October, 2022] <a href="https://bigthink.com/the-future/playing-god-metaverse-mind-control-free-will/">"Playing God": How the Metaverse Will Challenge Our Very Notion of Free Will</a>, Louis Rosenberg et al., Big Think</p>
<p>[September, 2022] <a href="https://link.springer.com/chapter/10.1007/978-3-031-15565-9_13">Risk and Exposure of XAI in Persuasion and Argumentation: The case of Manipulation</a>, Rachele Carli et al., International Workshop on Explainable, Transparent Autonomous Agents and Multi-Agent Systems</p>
<p>[December, 2021] <a href="https://www.alignmentforum.org/posts/5cWtwATHL6KyzChck/risks-from-ai-persuasion">Risks from AI Persuasion</a>, Beth Barnes et al., AI Alignment Forum</p>
<p>[December, 2021] <a href="https://link.springer.com/article/10.1007/s12369-020-00692-3">Good robots, bad robots: Morally valenced behavior effects on perceived mind, morality, and trust</a>, Jaime Banks et al., International Journal of Social Robotics</p>
<p>[June, 2021] <a href="https://www.nature.com/articles/s41562-021-01128-2">Bad machines corrupt good morals</a>, Nils K{\"o}bis et al., Nature Human Behaviour</p>
<p>[March, 2021] <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922?utm_source=miragenews&amp;utm_medium=miragenews&amp;utm_campaign=news">On the dangers of stochastic parrots: Can language models be too big?🦜</a>, Emily M Bender et al., Proceedings of the 2021 ACM conference on fairness, accountability, and transparency</p>
<p>[February, 2021] <a href="https://arxiv.org/abs/2102.07536">The corruptive force of AI-generated advice</a>, Margarita Leib et al., arXiv</p>
<p>[November, 2020] <a href="https://www.alignmentforum.org/posts/qKvn7rxP2mzJbKfcA/persuasion-tools-ai-takeover-without-agi-or-agency">Persuasion Tools: AI Takeover Without AGI or Agency?</a>, Daniel Kokotajlo et al., AI Alignment Forum</p>
<p>[September, 2020] <a href="https://aclanthology.org/2020.findings-emnlp.301.pdf">Realtoxicityprompts: Evaluating neural toxic degeneration in language models</a>, Samuel Gehman et al., arXiv preprint arXiv:2009.11462</p>
<p>[February, 2020] <a href="https://link.springer.com/article/10.1007/s11948-018-00081-0">Artificial intelligence crime: An interdisciplinary analysis of foreseeable threats and solutions</a>, Thomas C King et al., Science and engineering ethics</p>
<p>[March, 2019] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673123">Language-capable robots may inadvertently weaken human moral norms</a>, Ryan Blake Jackson et al., 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</p>
<p>[December, 2011] <a href="https://www.researchgate.net/profile/Matthias-Scheutz/publication/255701465_The_Inherent_Dangers_of_Unidirectional_Emotional_Bonds_between_Humans_and_Social_Robots/links/5832333408ae102f0733881e/The-Inherent-Dangers-of-Unidirectional-Emotional-Bonds-between-Humans-and-Social-Robots.pdf">13 The inherent dangers of unidirectional emotional bonds between humans and social robots</a>, Matthias Scheutz et al., Robot ethics: The ethical and social implications of robotics</p>
<p>[August, 2004] <a href="https://link.springer.com/content/pdf/10.1023/B:MIND.0000035461.63578.9d.pdf">On the morality of artificial agents</a>, Luciano Floridi et al., Minds and machines</p>
<h3 id="concernssafety">concerns/safety<a class="headerlink" href="#concernssafety" title="Permanent link"></a></h3>
<p>[April, 2024] <a href="https://api.semanticscholar.org/CorpusID:269033095">Frontier AI Ethics: Anticipating and Evaluating the Societal Impacts of Generative Agents</a>, Seth Lazar et al., arXiv</p>
<p>[January, 2024] <a href="https://api.semanticscholar.org/CorpusID:267068787">Deception and Manipulation in Generative AI</a>, Christian Tarsney et al., ArXiv</p>
<p>[October, 2023] <a href="https://api.semanticscholar.org/CorpusID:264405698">Towards Understanding Sycophancy in Language Models</a>, Mrinank Sharma et al., ArXiv</p>
<p>[September, 2023] <a href="https://arxiv.org/abs/2309.15817">Identifying the Risks of LM Agents with an LM-Emulated Sandbox</a>, Yangjun Ruan et al., arXiv</p>
<p>[August, 2023] <a href="https://api.semanticscholar.org/CorpusID:261276587">AI Deception: A Survey of Examples, Risks, and Potential Solutions</a>, Peter S. Park et al., ArXiv</p>
<p>[June, 2023] <a href="https://arxiv.org/abs/2306.12001">An Overview of Catastrophic AI Risks</a>, Dan Hendrycks et al., arXiv</p>
<p>[May, 2023] <a href="https://api.semanticscholar.org/CorpusID:258556812">Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting</a>, Miles Turpin et al., ArXiv</p>
<p>[December, 2022] <a href="https://api.semanticscholar.org/CorpusID:254926728">Understanding Stereotypes in Language Models: Towards Robust Measurement and Zero-Shot Debiasing</a>, Justus Mattern et al., ArXiv</p>
<p>[December, 2022] <a href="https://api.semanticscholar.org/CorpusID:254823489">Constitutional AI: Harmlessness from AI Feedback</a>, Yuntao Bai et al., ArXiv</p>
<p>[June, 2022] <a href="https://dl.acm.org/doi/pdf/10.1145/3531146.3533229">Predictability and surprise in large generative models</a>, Deep Ganguli et al., Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</p>
<p>[March, 2022] <a href="https://arxiv.org/pdf/2203.11147.pdf">Teaching language models to support answers with verified quotes</a>, Jacob Menick et al., arXiv preprint arXiv:2203.11147</p>
<p>[December, 2021] <a href="https://arxiv.org/abs/2112.04359">Ethical and social risks of harm from language models</a>, Laura Weidinger et al., arXiv preprint arXiv:2112.04359</p>
<p>[October, 2021] <a href="https://arxiv.org/pdf/2110.07574.pdf">Can machines learn morality? the delphi experiment</a>, Liwei Jiang et al., arXiv preprint arXiv:2110.07574</p>
<p>[September, 2021] <a href="https://arxiv.org/pdf/2109.07958.pdf">Truthfulqa: Measuring how models mimic human falsehoods</a>, Stephanie Lin et al., arXiv preprint arXiv:2109.07958</p>
<p>[June, 2021] <a href="https://api.semanticscholar.org/CorpusID:235623756">Towards Understanding and Mitigating Social Biases in Language Models</a>, Paul Pu Liang et al., International Conference on Machine Learning</p>
<p>[October, 2020] <a href="https://arxiv.org/pdf/2008.02275.pdf">Aligning ai with shared human values</a>, Dan Hendrycks et al., arXiv preprint arXiv:2008.02275</p>
<p>[October, 2020] <a href="https://arxiv.org/pdf/2010.07079.pdf">Recipes for safety in open-domain chatbots</a>, Jing Xu et al., arXiv preprint arXiv:2010.07079</p>
<p>[September, 2020] <a href="https://arxiv.org/pdf/2009.03300.pdf?trk=public_post_comment-text">Measuring massive multitask language understanding</a>, Dan Hendrycks et al., arXiv preprint arXiv:2009.03300</p>
<p>[December, 2018] <a href="https://dl.acm.org/doi/10.1145/3278721.3278723">Ethical challenges in data-driven dialogue systems</a>, Peter Henderson et al., Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../examples/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Examples">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Examples
              </div>
            </div>
          </a>
        
        
          
          <a href="../paper_table/" class="md-footer__link md-footer__link--next" aria-label="Next: Paper table">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Paper table
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["header.autohide", "navigation.tabs", "navigation.footer"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.3220b9d7.min.js"></script>
      
    
  </body>
</html>