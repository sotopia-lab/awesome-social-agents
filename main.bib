# Example of a paper entry
@misc{qian2023communicative,
      title={Communicative Agents for Software Development}, 
      author={Chen Qian and Xin Cong and Wei Liu and Cheng Yang and Weize Chen and Yusheng Su and Yufan Dang and Jiahao Li and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2023},
      url={https://arxiv.org/abs/2307.07924},
      environments = {collaboration, embodied},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {rule_based},
      other = {n/a},
      eprint={2307.07924},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
}
## Papers
### Surveys and Overview

### Environments

#### Text Environments

@article{environments/language,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@article{Bard_2020,
   title={The Hanabi challenge: A new frontier for AI research},
   volume={280},
   ISSN={0004-3702},
   url={http://dx.doi.org/10.1016/j.artint.2019.103216},
   DOI={10.1016/j.artint.2019.103216},
   journal={Artificial Intelligence},
   publisher={Elsevier BV},
   author={Bard, Nolan and Foerster, Jakob N. and Chandar, Sarath and Burch, Neil and Lanctot, Marc and Song, H. Francis and Parisotto, Emilio and Dumoulin, Vincent and Moitra, Subhodeep and Hughes, Edward and Dunning, Iain and Mourad, Shibl and Larochelle, Hugo and Bellemare, Marc G. and Bowling, Michael},
   year={2020},
   environments={collaboration, text},
   agents={more_than_three_agents},
   evaluation={rule_based},
   other={n/a},
   month={3}, pages={103216} }

@inproceedings{he-etal-2018-decoupling,
    title = "Decoupling Strategy and Generation in Negotiation Dialogues",
    author = "He, He  and
      Chen, Derek  and
      Balakrishnan, Anusha  and
      Liang, Percy",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = {10},
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1256",
    doi = "10.18653/v1/D18-1256",
    pages = "2333--2343",
    environments={text, mixed_objectives},
    agents={finetuning, reinforcement_learning, two_agents, agents_with_memory},
    evaluation={human},
    other={n/a}
}

@inproceedings{lewis-etal-2017-deal,
    title = "Deal or No Deal? End-to-End Learning of Negotiation Dialogues",
    author = "Lewis, Mike  and
      Yarats, Denis  and
      Dauphin, Yann  and
      Parikh, Devi  and
      Batra, Dhruv",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = {9},
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1259",
    doi = "10.18653/v1/D17-1259",
    pages = "2443--2453",
    environments={text, mixed_objectives},
    agents={reinforcement_learning, two_agents, agents_with_memory},
    evaluation={rule_based},
    other={human_agent}
}

@inproceedings{wang-etal-2019-persuasion,
    title = "Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good",
    author = "Wang, Xuewei  and
      Shi, Weiyan  and
      Kim, Richard  and
      Oh, Yoojung  and
      Yang, Sijia  and
      Zhang, Jingwen  and
      Yu, Zhou",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1566",
    doi = "10.18653/v1/P19-1566",
    pages = "5635--5649",
    abstract = "Developing intelligent persuasive conversational agents to change people{'}s opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals{'} demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individuals{'} personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.",
    environments={text, mixed_objectives},
    agents={two_agents, finetuning},
    evaluation={human, rule_based},
    other={human_agent}
}

@inproceedings{peskov-etal-2020-takes,
    title = "It Takes Two to Lie: One to Lie, and One to Listen",
    author = "Peskov, Denis  and
      Cheng, Benny  and
      Elgohary, Ahmed  and
      Barrow, Joe  and
      Danescu-Niculescu-Mizil, Cristian  and
      Boyd-Graber, Jordan",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.353",
    doi = "10.18653/v1/2020.acl-main.353",
    pages = "3811--3854",
    abstract = "Trust is implicit in many online text conversations{---}striking up new friendships, or asking for tech support. But trust can be betrayed through deception. We study the language and dynamics of deception in the negotiation-based game Diplomacy, where seven players compete for world domination by forging and breaking alliances with each other. Our study with players from the Diplomacy community gathers 17,289 messages annotated by the sender for their intended truthfulness and by the receiver for their perceived truthfulness. Unlike existing datasets, this captures deception in long-lasting relationships, where the interlocutors strategically combine truth with lies to advance objectives. A model that uses power dynamics and conversational contexts can predict when a lie occurs nearly as well as human players.",
    environments={text, mixed_objectives},
    agents={more_than_three_agents},
    evaluation={model_based},
    other={human_agent}
}

@article{LanctotEtAl2019OpenSpiel,
  title     = {{OpenSpiel}: A Framework for Reinforcement Learning in Games},
  author    = {Marc Lanctot and Edward Lockhart and Jean-Baptiste Lespiau and
               Vinicius Zambaldi and Satyaki Upadhyay and Julien P\'{e}rolat and
               Sriram Srinivasan and Finbarr Timbers and Karl Tuyls and
               Shayegan Omidshafiei and Daniel Hennes and Dustin Morrill and
               Paul Muller and Timo Ewalds and Ryan Faulkner and J\'{a}nos Kram\'{a}r
               and Bart De Vylder and Brennan Saeta and James Bradbury and David Ding
               and Sebastian Borgeaud and Matthew Lai and Julian Schrittwieser and
               Thomas Anthony and Edward Hughes and Ivo Danihelka and Jonah Ryan-Davis},
  month     = {8},
  year      = {2019},
  eprint    = {1908.09453},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  journal   = {CoRR},
  volume    = {abs/1908.09453},
  url       = {http://arxiv.org/abs/1908.09453},
  environments={collaboration, competition, mixed_objectives, text},
  agents={two_agents, more_than_three_agents, reinforcement_learning},
  evaluation={rule_based},
  other={n/a}
}

@article{zha2019rlcard,
  title={RLCard: A Toolkit for Reinforcement Learning in Card Games},
  author={Zha, Daochen and Lai, Kwei-Herng and Cao, Yuanpu and Huang, Songyi and Wei, Ruzhe and Guo, Junyu and Hu, Xia},
  journal={arXiv preprint arXiv:1910.04376},
  month = {7},
  year={2019},
  environments={collaboration, competition, mixed_objectives, text},
  agents={two_agents, more_than_three_agents, reinforcement_learning},
  evaluation={rule_based},
  other={n/a},
  url={https://github.com/datamllab/rlcard}
}

@article{meta2022human,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Meta Fundamental AI Research Diplomacy Team (FAIR)† and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1067--1074},
  month={11},
  year={2022},
  publisher={American Association for the Advancement of Science},
  url={https://www.science.org/doi/full/10.1126/science.ade9097},
  environments={competition, text},
  agents={more_than_three_agents, reinforcement_learning, finetuning},
  evaluation={rule_based},
  other={human_agent}
}

@software{multigrid,
  author = {Oguntola, Ini},
  title = {Fast Multi-Agent Gridworld Environments for Gymnasium},
  url = {https://github.com/ini/multigrid},
  month = {3},
  year = {2023},
  journal = {GitHub},
  environments={collaboration, competition, text},
  agents={two_agents, more_than_three_agents, reinforcement_learning},
  evaluation={rule_based},
  other={n/a}
}

@inproceedings{callison-burch-etal-2022-dungeons,
    title = "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
    author = "Callison-Burch, Chris  and
      Tomar, Gaurav Singh  and
      Martin, Lara  and
      Ippolito, Daphne  and
      Bailis, Suma  and
      Reitter, David",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.637",
    doi = "10.18653/v1/2022.emnlp-main.637",
    pages = "9379--9393",
    abstract = "AI researchers have posited Dungeons and Dragons (D{\&}D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D{\&}D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game{---}i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.",
    environments={text, implicit_objectives},
    agents={more_than_three_agents, pretraining, finetuning},
    evaluation={human, rule_based},
    other={human_agent}
}

@inproceedings{zhou-etal-2023-cast,
    title = "{I} Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons",
    author = "Zhou, Pei  and
      Zhu, Andrew  and
      Hu, Jennifer  and
      Pujara, Jay  and
      Ren, Xiang  and
      Callison-Burch, Chris  and
      Choi, Yejin  and
      Ammanabrolu, Prithviraj",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.624",
    doi = "10.18653/v1/2023.acl-long.624",
    pages = "11136--11155",
    abstract = "We propose a novel task, G4C, to study teacher-student natural language interactions in a goal-driven and grounded environment. Dungeons and Dragons (D{\&}D), a role-playing game, provides an ideal setting to investigate such interactions. Here, the Dungeon Master (DM), i.e., the teacher, guides the actions of several players{---}students, each with their own personas and abilities{---}to achieve shared goals grounded in a fantasy world. Our approach is to decompose and model these interactions into (1) the DM{'}s intent to guide players toward a given goal; (2) the DM{'}s guidance utterance to the players expressing this intent; and (3) a theory-of-mind (ToM) model that anticipates the players{'} reaction to the guidance one turn into the future. We develop a novel reinforcement learning (RL) method for training a DM that generates guidance for players by rewarding utterances where the intent matches the ToM-anticipated player actions. Human and automated evaluations show that a DM trained to explicitly model intents and incorporate ToM of the players using RL generates better-quality guidance that is 3x more likely to fulfill the DM{'}s intent than a vanilla natural language generation (NLG) approach.",
    environments={text, implicit_objectives},
    agents={more_than_three_agents, reinforcement_learning},
    evaluation={human, rule_based},
    other={human_agent}
}

@inproceedings{zhu-etal-2023-fireball,
    title = "{FIREBALL}: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information",
    author = "Zhu, Andrew  and
      Aggarwal, Karmanya  and
      Feng, Alexander  and
      Martin, Lara  and
      Callison-Burch, Chris",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.229",
    doi = "10.18653/v1/2023.acl-long.229",
    pages = "4171--4193",
    abstract = "Dungeons {\&} Dragons (D{\&}D) is a tabletop roleplaying game with complex natural language interactions between players and hidden state information. Recent work has shown that large language models (LLMs) that have access to state information can generate higher quality game turns than LLMs that use dialog history alone. However, previous work used game state information that was heuristically created and was not a true gold standard game state. We present FIREBALL, a large dataset containing nearly 25,000 unique sessions from real D{\&}D gameplay on Discord with true game state info. We recorded game play sessions of players who used the Avrae bot, which was developed to aid people in playing D{\&}D online, capturing language, game commands and underlying game state information. We demonstrate that FIREBALL can improve natural language generation (NLG) by using Avrae state information, improving both automated metrics and human judgments of quality. Additionally, we show that LLMs can generate executable Avrae commands, particularly after finetuning.",
    environments={text, implicit_objectives},
    agents={more_than_three_agents, finetuning},
    evaluation={human, rule_based},
    other={human_agent}
}

@inproceedings{zhu2023calypso,
   title={{CALYPSO}: {LLMs} as Dungeon Masters' Assistants},
   author={Zhu, Andrew and Martin, Lara J. and Head, Andrew and Callison-Burch, Chris},
   booktitle={The 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE 2023)},
   month={8},
   year={2023},
   environments={text, implicit_objectives},
   agents={more_than_three_agents, finetuning},
   evaluation={human},
   other={human_agent},
   url={https://arxiv.org/abs/2308.07540}
}

@article{eliza1966weizenbaum,
  author = {Weizenbaum, Joseph},
  title = {ELIZA—a computer program for the study of natural language communication between man and machine},
  year = {1966},
  issue_date = {Jan. 1966},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/365153.365168},
  doi = {10.1145/365153.365168},
  journal = {Commun. ACM},
  month = {jan},
  pages = {36–45},
  environments={text, mixed_objectives},
  agents={agents_with_personas},
  evaluation={human},
  other={n/a}
}

@article{shuster2022blenderbot,
  title={Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage},
  author={Shuster, Kurt and Xu, Jing and Komeili, Mojtaba and Ju, Da and Smith, Eric Michael and Roller, Stephen and Ung, Megan and Chen, Moya and Arora, Kushal and Lane, Joshua and others},
  journal={arXiv preprint arXiv:2208.03188},
  year={2022},
  month={8},
  url={https://arxiv.org/abs/2208.03188},
  environments={text, mixed_objectives},
  agents={finetuning},
  evaluation={qualitative, human},
  other={n/a}
}

@misc{introducing2022,
  title={Introducing ChatGPT},
  author={OpenAI},
  year={2022},
  month={11},
  url={https://openai.com/blog/chatgpt},
  journal={n/a},
  environments={text, mixed_objectives},
  agents={prompting_and_in_context_learning, agents_with_memory},
  evaluation={qualitative, human},
  other={human_agent}
}

@article{chiang2024chatbot,
  title={Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference},
  author={Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E and others},
  journal={arXiv preprint arXiv:2403.04132},
  year={2024},
  month={3},
  url={https://arxiv.org/abs/2403.04132},
  environments={text, mixed_objectives},
  agents={prompting_and_in_context_learning},
  evaluation={qualitative, human},
  other={human_agent}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022},
  month={5},
  url={https://arxiv.org/abs/2205.01068},
  environments={text, mixed_objectives},
  agents={finetuning, agents_with_personas},
  evaluation={qualitative, human},
  other={human_agent}
}

@article{zhou2020design,
  title = "The Design and Implementation of {X}iao{I}ce, an Empathetic Social Chatbot",
  author = "Zhou, Li  and
      Gao, Jianfeng  and
      Li, Di  and
      Shum, Heung-Yeung",
  journal = "Computational Linguistics",
  volume = "46",
  number = "1",
  year = "2020",
  month = "3",
  address = "Cambridge, MA",
  publisher = "MIT Press",
  url = "https://aclanthology.org/2020.cl-1.2",
  doi = "10.1162/coli_a_00368",
  pages = "53--93",
  environments={text, mixed_objectives},
  agents={finetuning, agents_with_personas},
  evaluation={qualitative, human},
  other={human_agent}
}

@incollection{cai2006empathic,
  title={Empathic computing},
  author={Cai, Yang},
  booktitle={Ambient intelligence in everyday life: Foreword by Emile Aarts},
  pages={67--85},
  year={2006},
  month={1},
  publisher={Springer},
  url={https://link.springer.com/chapter/10.1007/11825890_3},
  environments={text, mixed_objectives},
  agents={agents_with_personas},
  evaluation={human},
  other={n/a}
}

@inproceedings{dinan2018wizard,
  title={Wizard of Wikipedia: Knowledge-Powered Conversational Agents},
  author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},
  booktitle={International Conference on Learning Representations},
  year={2019},
  month={4},
  url={https://openreview.net/forum?id=r1l73iRqKm},
  environments={text, mixed_objectives, implicit_objectives},
  agents={finetuning, agents_with_personas},
  evaluation={qualitative, human},
  other={human_agent}
}

@inproceedings{ghazvininejad2018knowledge,
  title={A knowledge-grounded neural conversation model},
  author={Ghazvininejad, Marjan and Brockett, Chris and Chang, Ming-Wei and Dolan, Bill and Gao, Jianfeng and Yih, Wen-tau and Galley, Michel},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018},
  month={4},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/11977},
  environments={text, mixed_objectives, implicit_objectives},
  agents={finetuning},
  evaluation={qualitative, human},
  other={human_agent}
}

@article{li2016persona,
  title={A persona-based neural conversation model},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Spithourakis, Georgios P and Gao, Jianfeng and Dolan, Bill},
  journal={arXiv preprint arXiv:1603.06155},
  year={2016},
  month={8},
  url={https://aclanthology.org/P16-1094/},
  environments={text, mixed_objectives},
  agents={finetuning, agents_with_personas},
  evaluation={qualitative, human},
  other={human_agent}
}

@book{wallace2009anatomy,
  title={The anatomy of ALICE},
  author={Wallace, Richard S},
  year={2009},
  month={11},
  publisher={Springer},
  journal={n/a},
  url={https://link.springer.com/chapter/10.1007/978-1-4020-6710-5_13},
  environments={text, mixed_objectives},
  agents={agents_with_personas},
  evaluation={human},
  other={n/a}
}

@inproceedings{fung2018towards,
  title={Towards empathetic human-robot interactions},
  author={Fung, Pascale and Bertero, Dario and Wan, Yan and Dey, Anik and Chan, Ricky Ho Yin and Bin Siddique, Farhad and Yang, Yang and Wu, Chien-Sheng and Lin, Ruixi},
  booktitle={Computational Linguistics and Intelligent Text Processing: 17th International Conference, CICLing 2016, Konya, Turkey, April 3--9, 2016, Revised Selected Papers, Part II 17},
  pages={173--193},
  year={2018},
  month={3},
  organization={Springer},
  url={https://link.springer.com/chapter/10.1007/978-3-319-75487-1_14},
  environments={text, mixed_objectives},
  agents={agents_with_personas},
  evaluation={qualitative, human},
  other={human_agent}
}



#### Virtual Environments

@article{pan2024autonomous,
  title={Autonomous Evaluation and Refinement of Digital Agents},
  author={Pan, Jiayi and Zhang, Yichi and Tomlin, Nicholas and Zhou, Yifei and Levine, Sergey and Suhr, Alane},
  journal={arXiv preprint arXiv:2404.06474},
  year={2024},
  month={4},
  url={https://arxiv.org/abs/2404.06474v2},
  environments={virtual},
  agents={prompting_and_in_context_learning, finetuning},
  evaluation={qualitative},
  other={human_agent}
}

#### Embodied Environments

@article{team2024scaling,
  title={Scaling Instructable Agents Across Many Simulated Worlds},
  author={Team, SIMA and Abi Raad, Maria and Ahuja, Arun and Barros, Catarina and Besse, Frederic and Bolt, Andrew and Bolton, Adrian and Brownfield, Bethanie and Buttimore, Gavin and Cant, Max and others},
  year={2024},
  month={4},
  url={https://arxiv.org/abs/2404.10179v2},
  journal={arXiv preprint arXiv:2404.10179},
  environments={embodied},
  agents={prompting_and_in_context_learning, finetuning},
  evaluation={qualitative},
  other={human_agent}
}

@article{ma2023large,
  title={Large language models play starcraft ii: Benchmarks and a chain of summarization approach},
  author={Ma, Weiyu and Mi, Qirui and Yan, Xue and Wu, Yuqiao and Lin, Runji and Zhang, Haifeng and Wang, Jun},
  journal={arXiv preprint arXiv:2312.11865},
  year={2023},
  month={12},
  url={https://arxiv.org/abs/2312.11865},
  environments={embodied},
  agents={prompting_and_in_context_learning, finetuning},
  evaluation={qualitative},
  other={human_agent}
}

@misc{opengenerativeai2024evaluate,
  title={Evaluate LLMs in real time with Street Fighter III},
  author={OpenGenerativeAI team},
  year={2024},
  month={3},
  url={https://github.com/OpenGenerativeAI/llm-colosseum},
  journal={n/a},
  environments={embodied},
  agents={prompting_and_in_context_learning},
  evaluation={qualitative},
  other={human_agent}
}

@misc{zhao2023competeai,
      title={CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents}, 
      author={Qinlin Zhao and Jindong Wang and Yixuan Zhang and Yiqiao Jin and Kaijie Zhu and Hao Chen and Xing Xie},
      environments = {competition, text},
      agents = {prompting_and_in_context_learning, two_agents},
      evaluation = {rule_based},
      url = {https://arxiv.org/abs/2310.17512},
      other = {n/a},
      year={2023},
      eprint={2310.17512},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}



#### Virtual Environments
@article{environments/embodied,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

#### Embodied Environments
@article{environments/virtual,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}



@inproceedings{10.1145/3406499.3418760,
author = {Tsoi, Nathan and Hussein, Mohamed and Espinoza, Jeacy and Ruiz, Xavier and V\'{a}zquez, Marynel},
title = {SEAN: Social Environment for Autonomous Navigation},
year = {2020},
month={9},
isbn = {9781450380546},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406499.3418760},
doi = {10.1145/3406499.3418760},
abstract = {Social navigation research is performed on a variety of robotic platforms, scenarios, and environments. Making comparisons between navigation algorithms is challenging because of the effort involved in building these systems and the diversity of platforms used by the community; nonetheless, evaluation is critical to understanding progress in the field. In a step towards reproducible evaluation of social navigation algorithms, we propose the Social Environment for Autonomous Navigation (SEAN). SEAN is a high visual fidelity, open source, and extensible social navigation simulation platform which includes a toolkit for evaluation of navigation algorithms. We demonstrate SEAN and its evaluation toolkit in two environments with dynamic pedestrians and using two different robots.},
booktitle = {Proceedings of the 8th International Conference on Human-Agent Interaction},
pages = {281–283},
numpages = {3},
keywords = {social robot navigation, human-robot interaction},
location = {Virtual Event, USA},
series = {HAI '20},
environments={mixed_objectives, embodied},
agents={reinforcement_learning},
evaluation={rule_based},
other={human_agent, simulated_humans}
}

@inproceedings{puig2024habitat,
title={Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots},
author={Xavier Puig and Eric Undersander and Andrew Szot and Mikael Dallaire Cote and Tsung-Yen Yang and Ruslan Partsey and Ruta Desai and Alexander Clegg and Michal Hlavac and So Yeon Min and Vladim{\'\i}r Vondru{\v{s}} and Theophile Gervet and Vincent-Pierre Berges and John M Turner and Oleksandr Maksymets and Zsolt Kira and Mrinal Kalakrishnan and Jitendra Malik and Devendra Singh Chaplot and Unnat Jain and Dhruv Batra and Akshara Rai and Roozbeh Mottaghi},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
month={10},
url={https://openreview.net/forum?id=4znwzG92CE},
  environments={mixed_objectives, embodied},
  agents={reinforcement_learning},
  evaluation={rule_based},
  other={human_agent, simulated_humans}
}






#### Robotics
@article{environments/robotics,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@InProceedings{pmlr-v205-xiong23a,
    title = {RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments},
    author = {Xiong, Haoyu and Fu, Haoyuan and Zhang, Jieyi and Bao, Chen and Zhang, Qiang and Huang, Yongxi and Xu, Wenqiang and Garg, Animesh and Lu, Cewu},
    booktitle = {Proceedings of The 6th Conference on Robot Learning},
    pages = {1--10},
    year = {2023},
    editor = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
    volume = {205},
    series = {Proceedings of Machine Learning Research},
    month = {12},
    publisher =  {PMLR},
    pdf = {https://proceedings.mlr.press/v205/xiong23a/xiong23a.pdf},
    url = {https://proceedings.mlr.press/v205/xiong23a.html},
    environments = {implicit_objectives, robotics},
    agents = {reinforcement_learning, agents_with_memory},
    evaluation = {human, rule_based},
    other = {simulated_humans}
}


@inproceedings{saycan2022arxiv,
    title={Do As I Can and Not As I Say: Grounding Language in Robotic Affordances},
    author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
    booktitle={arXiv preprint arXiv:2204.01691},
    year={2022},
    month={8},
    url = {https://say-can.github.io/},
    environments = {mixed_objectives, implicit_objectives, robotics},
    agents = {finetuning, reinforcement_learning, agents_with_memory},
    evaluation = {human, rule_based, model_based},
    other = {simulated_humans}
}

@inproceedings{huang2022inner,
    title={Inner Monologue: Embodied Reasoning through Planning with Language Models},
    author={Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and Pierre Sermanet and Noah Brown and Tomas Jackson and Linda Luu and Sergey Levine and Karol Hausman and Brian Ichter},
    booktitle={arXiv preprint arXiv:2207.05608},
    year={2022},
    month={6},
    url = {https://arxiv.org/abs/2207.05608},
    environments = {mixed_objectives, implicit_objectives, robotics},
    agents = {finetuning, reinforcement_learning, agents_with_memory},
    evaluation = {human, rule_based, model_based},
    other = {simulated_humans}
}

@inproceedings{Wang2023One,
    title={One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments},
    author={Wang, Yufei and Sun, Zhanyi and Erickson, Zackory and Held, David},
    booktitle={Robotics: Science and Systems (RSS)},
    year={2023},
    month={6},
    url = {https://arxiv.org/abs/2306.12372},
    environments = {robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}     

@misc{wang2023cogail,
    title={Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration}, 
    author={Chen Wang and Claudia Pérez-D'Arpino and Danfei Xu and Li Fei-Fei and C. Karen Liu and Silvio Savarese},
    year={2023},
    month={9},
    url = {https://arxiv.org/abs/2108.06038},
    eprint={2108.06038},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, reinforcement_learning},
    evaluation = {human},
    other = {human_agent, simulated_humans}
}

@misc{shi2024yell,
    title={Yell At Your Robot: Improving On-the-Fly from Language Corrections}, 
    author={Lucy Xiaoyang Shi and Zheyuan Hu and Tony Z. Zhao and Archit Sharma and Karl Pertsch and Jianlan Luo and Sergey Levine and Chelsea Finn},
    year={2024},
    month={3},
    url={https://arxiv.org/abs/2403.12910},
    eprint={2403.12910},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, finetuning, reinforcement_learning, agents_with_memory},
    evaluation = {human},
    other = {human_agent}
}

@article{sheridan2016human,
    title={Human--robot interaction: status and challenges},
    author={Sheridan, Thomas B},
    journal={Human factors},
    month={4},
    url={https://journals.sagepub.com/doi/10.1177/0018720816644364},
    volume={58},
    number={4},
    pages={525--532},
    year={2016},
    publisher={SAGE Publications Sage CA: Los Angeles, CA},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, finetuning, reinforcement_learning},
    evaluation = {human},
    other = {human_agent}
}


@article{onnasch2021taxonomy,
    title={A taxonomy to structure and analyze human--robot interaction},
    author={Onnasch, Linda and Roesler, Eileen},
    journal={International Journal of Social Robotics},
    volume={13},
    number={4},
    pages={833--849},
    year={2021},
    publisher={Springer},
    month={6},
    url={https://link.springer.com/article/10.1007/s12369-020-00666-5},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents},
    evaluation = {human},
    other = {human_agent}
}

@article{robinson2023robotic,
    title={Robotic vision for human-robot interaction and collaboration: A survey and systematic review},
    author={Robinson, Nicole and Tidd, Brendan and Campbell, Dylan and Kuli{\'c}, Dana and Corke, Peter},
    journal={ACM Transactions on Human-Robot Interaction},
    volume={12},
    number={1},
    pages={1--66},
    year={2023},
    month={7},
    url={https://arxiv.org/abs/2307.15363},
    publisher={ACM New York, NY},
    environments = {collaboration, mixed_objectives, implicit_objectives, robotics},
    agents = {two_agents, agent_teams, agents_with_personas},
    evaluation = {human, rule_based},
    other = {human_agent, simulated_humans}
}

@article{dahiya2023survey,
    title={A survey of multi-agent Human--Robot Interaction systems},
    author={Dahiya, Abhinav and Aroyo, Alexander M and Dautenhahn, Kerstin and Smith, Stephen L},
    journal={Robotics and Autonomous Systems},
    volume={161},
    pages={104335},
    year={2022},
    month={10},
    url={https://arxiv.org/abs/2212.05286},
    publisher={Elsevier},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, more_than_three_agents, agent_teams},
    evaluation = {human},
    other = {human_agent}
}

@article{10.1145/3570169,
    author = {Urakami, Jacqueline and Seaborn, Katie},
    title = {Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective},
    year = {2023},
    issue_date = {June 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {12},
    number = {2},
    url = {https://doi.org/10.1145/3570169},
    doi = {10.1145/3570169},
    journal = {J. Hum.-Robot Interact.},
    month = {3},
    articleno = {22},
    numpages = {21},
    keywords = {nonverbal codes, communication studies, human robot interaction, nonverbal communication, Robotics},
    environments = {collaboration, mixed_objectives, implicit_objectives, robotics},
    agents = {two_agents},
    evaluation = {human},
    other = {human_agent}
}

@article{10.1145/3571718,
    author = {Winkle, Katie and Lagerstedt, Erik and Torre, Ilaria and Offenwanger, Anna},
    title = {15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction},
    year = {2023},
    issue_date = {September 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {12},
    number = {3},
    url = {https://doi.org/10.1145/3571718},
    doi = {10.1145/3571718},
    abstract = {Recent work identified a concerning trend of disproportional gender representation in research participants in Human–Computer Interaction (HCI). Motivated by the fact that Human–Robot Interaction (HRI) shares many participant practices with HCI, we explored whether this trend is mirrored in our field. By producing a dataset covering participant gender representation in all 684 full papers published at the HRI conference from 2006–2021, we identify current trends in HRI research participation. We find an over-representation of men in research participants to date, as well as inconsistent and/or incomplete gender reporting, which typically engages in a binary treatment of gender at odds with published best practice guidelines. We further examine if and how participant gender has been considered in user studies to date, in-line with current discourse surrounding the importance and/or potential risks of gender based analyses. Finally, we complement this with a survey of HRI researchers to examine correlations between who is doing with the who is taking part, to further reflect on factors which seemingly influence gender bias in research participation across different sub-fields of HRI. Through our analysis, we identify areas for improvement, but also reason for optimism, and derive some practical suggestions for HRI researchers going forward.},
    journal = {J. Hum.-Robot Interact.},
    month = {4},
    articleno = {28},
    numpages = {28},
    keywords = {Gender, systematic review, user study methodologies, participant recruitment, inclusivity},
    environments = {robotics},
    agents = {two_agents},
    evaluation = {human},
    other = {human_agent}
}

### Modeling

#### In-context Learning
@article{modeling/in-context-learning,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@misc{wang2023voyager,
    title={Voyager: An Open-Ended Embodied Agent with Large Language Models}, 
    author={Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
    year={2023},
    month={5},
    url={https://arxiv.org/abs/2305.16291},
    eprint={2305.16291},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    environments = {mixed_objectives, implicit_objectives, embodied},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{kim2023language,
    title={Language Models can Solve Computer Tasks}, 
    author={Geunwoo Kim and Pierre Baldi and Stephen McAleer},
    year={2023},
    month={11},
    url={https://arxiv.org/abs/2303.17491},
    eprint={2303.17491},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{ma2024laser,
    title={LASER: LLM Agent with State-Space Exploration for Web Navigation}, 
    author={Kaixin Ma and Hongming Zhang and Hongwei Wang and Xiaoman Pan and Wenhao Yu and Dong Yu},
    year={2024},
    month={2},
    url={https://arxiv.org/abs/2309.08172},
    eprint={2309.08172},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{sridhar2023hierarchical,
    title={Hierarchical Prompting Assists Large Language Model on Web Navigation}, 
    author={Abishek Sridhar and Robert Lo and Frank F. Xu and Hao Zhu and Shuyan Zhou},
    year={2023},
    month={10},
    url={https://arxiv.org/abs/2305.14257},
    eprint={2305.14257},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{zheng2024synapse,
    title={Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control},
    author={Longtao Zheng and Rundong Wang and Xinrun Wang and Bo An},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    month={1},
    url={https://openreview.net/forum?id=Pc8AU1aF5e},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{sun2023adaplanner,
    title={AdaPlanner: Adaptive Planning from Feedback with Language Models},
    author={Haotian Sun and Yuchen Zhuang and Lingkai Kong and Bo Dai and Chao Zhang},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    month={11},
    url={https://openreview.net/forum?id=rnKgbKmelt},
    environments = {mixed_objectives, implicit_objectives, text},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{wu2023spring,
    title={SPRING: Studying the Paper and Reasoning to Play Games}, 
    author={Yue Wu and Shrimai Prabhumoye and So Yeon Min and Yonatan Bisk and Ruslan Salakhutdinov and Amos Azaria and Tom Mitchell and Yuanzhi Li},
    year={2023},
    month={5},
    url={https://arxiv.org/abs/2305.15486},
    eprint={2305.15486},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    environments = {mixed_objectives, implicit_objectives, text},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{nair2023dera,
    title={DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents}, 
    author={Varun Nair and Elliot Schumacher and Geoffrey Tso and Anitha Kannan},
    year={2023},
    month={3},
    url={https://arxiv.org/abs/2303.17071},
    eprint={2303.17071},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {collaboration, mixed_objectives, implicit_objectives, text},
    agents = {prompting_and_in_context_learning, agent_teams, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}
#### Finetuning
@article{modeling/finetuning,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@misc{gur2023understanding,
    title={Understanding HTML with Large Language Models}, 
    author={Izzeddin Gur and Ofir Nachum and Yingjie Miao and Mustafa Safdari and Austin Huang and Aakanksha Chowdhery and Sharan Narang and Noah Fiedel and Aleksandra Faust},
    year={2023},
    month={5},
    url={https://arxiv.org/abs/2210.03945},
    eprint={2210.03945},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{
    furuta2023instructionfinetuned,
    title={Instruction-Finetuned Foundation Models for Multimodal Web Navigation},
    author={Hiroki Furuta and Ofir Nachum and Kuang-Huei Lee and Yutaka Matsuo and Shixiang Shane Gu and Izzeddin Gur},
    booktitle={ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models},
    year={2023},
    month={5},
    url={https://openreview.net/forum?id=oLc9sGOBbc},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{yao2023react,
    title={ReAct: Synergizing Reasoning and Acting in Language Models}, 
    author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
    year={2023},
    month={10},
    eprint={2210.03629},
    url={https://arxiv.org/abs/2210.03629},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{gur2024a,
    title={A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis},
    author={Izzeddin Gur and Hiroki Furuta and Austin V Huang and Mustafa Safdari and Yutaka Matsuo and Douglas Eck and Aleksandra Faust},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    month={1},
    url={https://openreview.net/forum?id=9JQtrumvg8},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{shaw2023from,
    title={From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces},
    author={Peter Shaw and Mandar Joshi and James Cohan and Jonathan Berant and Panupong Pasupat and Hexiang Hu and Urvashi Khandelwal and Kenton Lee and Kristina Toutanova},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    month={11},
    url={https://openreview.net/forum?id=3PjCt4kmRx},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{zheng2024gpt4vision,
    title={GPT-4V(ision) is a Generalist Web Agent, if Grounded}, 
    author={Boyuan Zheng and Boyu Gou and Jihyung Kil and Huan Sun and Yu Su},
    year={2024},
    month={1},
    url={https://arxiv.org/abs/2401.01614},
    eprint={2401.01614},
    archivePrefix={arXiv},
    primaryClass={cs.IR},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{kil2024dualview,
    title={Dual-View Visual Contextualization for Web Navigation}, 
    author={Jihyung Kil and Chan Hee Song and Boyuan Zheng and Xiang Deng and Yu Su and Wei-Lun Chao},
    year={2024},
    month={2},
    url={https://arxiv.org/abs/2402.04476},
    eprint={2402.04476},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

#### Reinforcement learning
@article{modeling/reinforcement-learning,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@article{van2022language,
  title={Language games meet multi-agent reinforcement learning: A case study for the naming game},
  author={Van Eecke, Paul and Beuls, Katrien and Botoko Ekila, J{\'e}r{\^o}me and R{\u{a}}dulescu, Roxana},
  journal={Journal of Language Evolution},
  volume={7},
  number={2},
  pages={213--223},
  month={4},
  year={2022},
  url={https://academic.oup.com/jole/article/7/2/213/7128304},
  publisher={Oxford University Press UK},
  environments={collaboration, competition, mixed_objectives},
  agents={reinforcement_learning, two_agents},
  evaluation={rule_based},
  other={n/a}
}

@inproceedings{zhu2022language,
  title={Language Learning from Communicative Goals and Linguistic Input},
  author={Zhu, Hao and Bisk, Yonatan and Neubig, Graham},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={44},
  number={44},
  year={2022},
  month={7},
  url={https://escholarship.org/uc/item/7p65n371},
  environments={collaboration, virtual},
  agents={reinforcement_learning, two_agents},
  evaluation={rule_based},
  other={simulated_humans}
}

@misc{wang2024sotopiapi,
      title={SOTOPIA-$\pi$: Interactive Learning of Socially Intelligent Language Agents}, 
      author={Ruiyi Wang and Haofei Yu and Wenxin Zhang and Zhengyang Qi and Maarten Sap and Graham Neubig and Yonatan Bisk and Hao Zhu},
      year={2024},
      eprint={2403.08715},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      environments = {collaboration, competition, mixed_objectives, text},
      agents = {reinforcement_learning, two_agents},
      evaluation = {rule_based, human, model_based},
      other = {simulated_humans},
      url = {https://arxiv.org/abs/2403.08715}
}

@misc{liu2023computational,
      title={Computational Language Acquisition with Theory of Mind}, 
      author={Andy Liu and Hao Zhu and Emmy Liu and Yonatan Bisk and Graham Neubig},
      year={2023},
      eprint={2303.01502},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      environments = {collaboration, virtual},
      agents = {reinforcement_learning, two_agents},
      evaluation = {rule_based},
      other = {simulated_humans},
      url = {https://arxiv.org/abs/2303.01502}
}


@article{zhe2024indentifying,
	abstract = {Identifying key patterns of tactics implemented by rival teams, and developing effective responses, lies at the heart of modern football. However, doing so algorithmically remains an open research challenge. To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC. We focus on analysing corner kicks, as they offer coaches the most direct opportunities for interventions and improvements. TacticAI incorporates both a predictive and a generative component, allowing the coaches to effectively sample and explore alternative player setups for each corner kick routine and to select those with the highest predicted likelihood of success. We validate TacticAI on a number of relevant benchmark tasks: predicting receivers and shot attempts and recommending player position adjustments. The utility of TacticAI is validated by a qualitative study conducted with football domain experts at Liverpool FC. We show that TacticAI's model suggestions are not only indistinguishable from real tactics, but also favoured over existing tactics 90{\%} of the time, and that TacticAI offers an effective corner kick retrieval system. TacticAI achieves these results despite the limited availability of gold-standard data, achieving data efficiency through geometric deep learning.},
	author = {Wang, Zhe and Veli{\v c}kovi{\'c}, Petar and Hennes, Daniel and Toma{\v s}ev, Nenad and Prince, Laurel and Kaisers, Michael and Bachrach, Yoram and Elie, Romuald and Wenliang, Li Kevin and Piccinini, Federico and Spearman, William and Graham, Ian and Connor, Jerome and Yang, Yi and Recasens, Adri{\`a} and Khan, Mina and Beauguerlange, Nathalie and Sprechmann, Pablo and Moreno, Pol and Heess, Nicolas and Bowling, Michael and Hassabis, Demis and Tuyls, Karl},
	date = {2024/03/19},
	date-added = {2024-04-19 16:43:21 -0400},
	date-modified = {2024-04-19 16:43:21 -0400},
	doi = {10.1038/s41467-024-45965-x},
	id = {Wang2024},
	isbn = {2041-1723},
	journal = {Nature Communications},
	number = {1},
	pages = {1906},
	title = {TacticAI: an AI assistant for football tactics},
	url = {https://doi.org/10.1038/s41467-024-45965-x},
	volume = {15},
	year = {2024},
  month={3},
  environments = {virtual, collaboration, competition, mixed_objectives},
  agents = {reinforcement_learning, agent_teams},
  evaluation = {rule_based},
  other = {n/a},
	bdsk-url-1 = {https://doi.org/10.1038/s41467-024-45965-x}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group},
  month={4},
  url={https://www.nature.com/articles/nature24270},
  environments = {competition, virtual},
  agents = {reinforcement_learning},
  evaluation = {rule_based},
  other = {human_agent},
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group},
  month={1},
  url={https://www.nature.com/articles/nature16961},
  environments = {competition, virtual},
  agents = {reinforcement_learning},
  evaluation = {rule_based},
  other = {human_agent},
}

@inproceedings{kharitonov-etal-2019-egg,
    title = "{EGG}: a toolkit for research on Emergence of lan{G}uage in Games",
    author = "Kharitonov, Eugene  and
      Chaabouni, Rahma  and
      Bouchacourt, Diane  and
      Baroni, Marco",
    editor = "Pad{\'o}, Sebastian  and
      Huang, Ruihong",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-3010",
    doi = "10.18653/v1/D19-3010",
    pages = "55--60",
    abstract = "There is renewed interest in simulating language emergence among deep neural agents that communicate to jointly solve a task, spurred by the practical aim to develop language-enabled interactive AIs, as well as by theoretical questions about the evolution of human language. However, optimizing deep architectures connected by a discrete communication channel (such as that in which language emerges) is technically challenging. We introduce EGG, a toolkit that greatly simplifies the implementation of emergent-language communication games. EGG{'}s modular design provides a set of building blocks that the user can combine to create new games, easily navigating the optimization and architecture space. We hope that the tool will lower the technical barrier, and encourage researchers from various backgrounds to do original work in this exciting area.",
    environments = {collaboration, text},
    agents = {reinforcement_learning, two_agents},
    evaluation = {rule_based},
    other = {n/a}
}

@inproceedings{ cao2018emergent,
  title={Emergent Communication through Negotiation},
  author={Kris Cao and Angeliki Lazaridou and Marc Lanctot and Joel Z Leibo and Karl Tuyls and Stephen Clark},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=Hk6WhagRW},
  month={2},
  environments = {mixed_objectives, text},
  agents = {reinforcement_learning, two_agents},
  evaluation = {rule_based},
  other = {n/a}
}

@inproceedings{10.1145/3269206.3272021,
  author = {Jin, Junqi and Song, Chengru and Li, Han and Gai, Kun and Wang, Jun and Zhang, Weinan},
  title = {Real-Time Bidding with Multi-Agent Reinforcement Learning in Display Advertising},
  year = {2018},
  isbn = {9781450360142},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3269206.3272021},
  doi = {10.1145/3269206.3272021},
  abstract = {Real-time advertising allows advertisers to bid for each impression for a visiting user. To optimize specific goals such as maximizing revenue and return on investment (ROI) led by ad placements, advertisers not only need to estimate the relevance between the ads and user's interests, but most importantly require a strategic response with respect to other advertisers bidding in the market. In this paper, we formulate bidding optimization with multi-agent reinforcement learning. To deal with a large number of advertisers, we propose a clustering method and assign each cluster with a strategic bidding agent. A practical Distributed Coordinated Multi-Agent Bidding (DCMAB) has been proposed and implemented to balance the tradeoff between the competition and cooperation among advertisers. The empirical study on our industry-scaled real-world data has demonstrated the effectiveness of our methods. Our results show cluster-based bidding would largely outperform single-agent and bandit approaches, and the coordinated bidding achieves better overall objectives than purely self-interested bidding agents.},
  booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  pages = {2193–2201},
  numpages = {9},
  keywords = {real-time bidding, multi-agent reinforcement learning, display advertising, bid optimization},
  location = {Torino, Italy},
  series = {CIKM '18},
  month = oct,
  environments = {competition, virtual},
  agents = {reinforcement_learning, more_than_three_agents},
  evaluation = {rule_based},
  other = {n/a}
}


### Evaluating social agents

#### Evaluating text social agents
@article{evaluation/language,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@inproceedings{zhou2024sotopia,
  title={SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents},
  author={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},
  booktitle={ICLR},
  environments = {mixed_objectives, text},
  agents = {prompting_and_in_context_learning, two_agents},
  evaluation = {model_based, human},
  other = {human_agent},
  year={2024},
  month = {10},
  url={https://openreview.net/forum?id=mM7VurbA4r}
}

@misc{chen2024roleinteract,
      title={RoleInteract: Evaluating the Social Interaction of Role-Playing Agents}, 
      author={Hongzhan Chen and Hehong Chen and Ming Yan and Wenshen Xu and Xing Gao and Weizhou Shen and Xiaojun Quan and Chenliang Li and Ji Zhang and Fei Huang and Jingren Zhou},
      year={2024},
      environments = {implicit_objectives, text},
      agents = {prompting_and_in_context_learning, more_than_three_agents, agents_with_memory, agents_with_personas},
      evaluation = {rule_based},
      other = {simulated_humans},
      url = {https://arxiv.org/abs/2403.13679},
      eprint={2403.13679},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{svikhnushina-pu-2023-approximating,
      title = "Approximating Online Human Evaluation of Social Chatbots with Prompting",
      author = "Svikhnushina, Ekaterina  and
            Pu, Pearl",
      editor = "Stoyanchev, Svetlana  and
            Joty, Shafiq  and
            Schlangen, David  and
            Dusek, Ondrej  and
            Kennington, Casey  and
            Alikhani, Malihe",
      booktitle = "Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
      month = {09},
      year = "2023",
      address = "Prague, Czechia",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2023.sigdial-1.25",
      doi = "10.18653/v1/2023.sigdial-1.25",
      pages = "268--281",
      abstract = "With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.",
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, two_agents},
      evaluation = {model_based},
      other = {n/a}
}

@inproceedings{NEURIPS2023_a3621ee9,
      author = {Li, Guohao and Hammoud, Hasan and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
      booktitle = {Advances in Neural Information Processing Systems},
      editor = {A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
      pages = {51991--52008},
      publisher = {Curran Associates, Inc.},
      title = {CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society},
      url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/a3621ee907def47c1b952ade25c67698-Paper-Conference.pdf},
      volume = {36},
      year = {2023},
      month = {12},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, agent_teams},
      evaluation = {human, model_based},
      other = {human_agent}
}

@article{lan2023llm,
      title={Llm-based agent society investigation: Collaboration and confrontation in avalon gameplay},
      author={Lan, Yihuai and Hu, Zhiqiang and Wang, Lei and Wang, Yang and Ye, Deheng and Zhao, Peilin and Lim, Ee-Peng and Xiong, Hui and Wang, Hao},
      journal={arXiv preprint arXiv:2310.14985},
      eprint={2310.14985},
      year={2023},
      month={10},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, more_than_three_agents, agents_with_memory, agents_with_personas},
      evaluation = {model_based, rule_based},
      other = {simulated_humans},
      url = {https://arxiv.org/pdf/2310.14985.pdf}
}

@misc{tu2023characterchat,
      title={CharacterChat: Learning towards Conversational AI with Personalized Social Support}, 
      author={Quan Tu and Chuanqi Chen and Jinpeng Li and Yanran Li and Shuo Shang and Dongyan Zhao and Ran Wang and Rui Yan},
      year={2023},
      month={08},
      environments = {implicit_objectives, text},
      agents = {prompting_and_in_context_learning, two_agents, agents_with_memory, agents_with_personas},
      evaluation = {model_based, human},
      other = {simulated_humans},
      url = {https://arxiv.org/abs/2308.10278},
      eprint={2308.10278},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2023agentcf,
      title={AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems}, 
      author={Junjie Zhang and Yupeng Hou and Ruobing Xie and Wenqi Sun and Julian McAuley and Wayne Xin Zhao and Leyu Lin and Ji-Rong Wen},
      year={2023},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, more_than_three_agents, agents_with_memory, agents_with_personas},
      evaluation = {rule_based},
      other = {simulated_humans},
      url = {https://arxiv.org/abs/2310.09233},
      eprint={2310.09233},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{huang2024far,
      title={How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments}, 
      author={Jen-tse Huang and Eric John Li and Man Ho Lam and Tian Liang and Wenxuan Wang and Youliang Yuan and Wenxiang Jiao and Xing Wang and Zhaopeng Tu and Michael R. Lyu},
      year={2024},
      eprint={2403.11807},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2403.11807},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {rule_based},
      other = {more_omniscient}
}

@misc{chan2023chateval,
      title={ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate}, 
      author={Chi-Min Chan and Weize Chen and Yusheng Su and Jianxuan Yu and Wei Xue and Shanghang Zhang and Jie Fu and Zhiyuan Liu},
      year={2023},
      eprint={2308.07201},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.07201},
      environments = {collaboration, text},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {rule_based},
      other = {n/a}
}

@misc{li2024automatic,
      title={Automatic Evaluation for Mental Health Counseling using LLMs}, 
      author={Anqi Li and Yu Lu and Nirui Song and Shuai Zhang and Lizhi Ma and Zhenzhong Lan},
      year={2024},
      eprint={2402.11958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
        url={https://arxiv.org/abs/2402.11958},
        environments = {collaboration, text},
        agents = {prompting_and_in_context_learning, two_agents},
        evaluation = {model_based},
        other = {n/a}
}

@misc{bianchi2024llms,
      title={How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis}, 
      author={Federico Bianchi and Patrick John Chia and Mert Yuksekgonul and Jacopo Tagliabue and Dan Jurafsky and James Zou},
      year={2024},
      eprint={2402.05863},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
        url={https://arxiv.org/abs/2402.05863},
        environments = {mixed_objectives, text},
        agents = {prompting_and_in_context_learning, two_agents},
        evaluation = {rule_based},
        other = {more_information_asymmetrical}
}

@inproceedings{Jiang2023PersonaLLMIT,
  title={PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits},
  author={Hang Jiang and Xiajie Zhang and Xubo Cao and Cynthia Breazeal and Deb Roy and Jad Kabbara},
  year={2023},
  booktitle={NAACL Findings},
  url={https://api.semanticscholar.org/CorpusID:268032940},
  environments = {text},
  agents = {prompting_and_in_context_learning},
  evaluation = {human, model_based},
  other = {n/a}, 
  month={5}
}

@article{Xie2024CanLL,
  title={Can Large Language Model Agents Simulate Human Trust Behaviors?},
  author={Chengxing Xie and Canyu Chen and Feiran Jia and Ziyu Ye and Kai Shu and Adel Bibi and Ziniu Hu and Philip H.S. Torr and Bernard Ghanem and G. Li},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.04559},
  url={https://api.semanticscholar.org/CorpusID:267523076},
    environments = {text},
    agents = {prompting_and_in_context_learning},
    evaluation = {human, model_based},
    other = {n/a},
    month={2}
}

@article{Rasal2024LLMHM,
  title={LLM Harmony: Multi-Agent Communication for Problem Solving},
  author={Sumedh Rasal},
  journal={ArXiv},
  year={2024},
  volume={abs/2401.01312},
  url={https://api.semanticscholar.org/CorpusID:266725580},
    environments = {text},
    agents = {prompting_and_in_context_learning},
    evaluation = {human, model_based},
    other = {n/a},
    month={1}
}

@inproceedings{yeh-etal-2021-comprehensive,
    title = "A Comprehensive Assessment of Dialog Evaluation Metrics",
    author = "Yeh, Yi-Ting  and
      Eskenazi, Maxine  and
      Mehri, Shikib",
    editor = "Wei, Wei  and
      Dai, Bo  and
      Zhao, Tuo  and
      Li, Lihong  and
      Yang, Diyi  and
      Chen, Yun-Nung  and
      Boureau, Y-Lan  and
      Celikyilmaz, Asli  and
      Geramifard, Alborz  and
      Ahuja, Aman  and
      Jiang, Haoming",
    booktitle = "The First Workshop on Evaluations and Assessments of Neural Conversation Systems",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eancs-1.3",
    environments = {text},
    agents = {n/a},
    evaluation = {human, model_based, rule_based},
    other = {n/a}
}

@inproceedings{chang-etal-2020-convokit,
    title = "{C}onvo{K}it: A Toolkit for the Analysis of Conversations",
    author = "Chang, Jonathan P.  and
      Chiam, Caleb  and
      Fu, Liye  and
      Wang, Andrew  and
      Zhang, Justine  and
      Danescu-Niculescu-Mizil, Cristian",
    editor = "Pietquin, Olivier  and
      Muresan, Smaranda  and
      Chen, Vivian  and
      Kennington, Casey  and
      Vandyke, David  and
      Dethlefs, Nina  and
      Inoue, Koji  and
      Ekstedt, Erik  and
      Ultes, Stefan",
    booktitle = "Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = jul,
    year = "2020",
    address = "1st virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.sigdial-1.8",
    doi = "10.18653/v1/2020.sigdial-1.8",
    pages = "57--60",
    environments = {text},
    agents = {n/a},
    evaluation = {human, model_based, rule_based},
    other = {n/a}
}

@misc{giorgi2023psychological,
      title={Psychological Metrics for Dialog System Evaluation}, 
      author={Salvatore Giorgi and Shreya Havaldar and Farhan Ahmed and Zuhaib Akhtar and Shalaka Vaidya and Gary Pan and Lyle H. Ungar and H. Andrew Schwartz and Joao Sedoc},
      year={2023},
      environments = {text},
      agents = {two_agents},
      evaluation = {human, rule_based},
      other = {human_agent},
      url = {https://arxiv.org/abs/2305.14757},
      eprint={2305.14757},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{ghazarian2023accent,
      title={ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems}, 
      author={Sarik Ghazarian and Yijia Shao and Rujun Han and Aram Galstyan and Nanyun Peng},
      year={2023},
      environments = {text},
      agents = {two_agents},
      evaluation = {human, model_based},
      other = {human_agent},
      url = {https://arxiv.org/pdf/2305.07797},
      eprint={2305.07797},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{huang-etal-2020-grade,
      title = "{GRADE}: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems",
      author = "Huang, Lishan  and
            Ye, Zheng  and
            Qin, Jinghui  and
            Lin, Liang  and
            Liang, Xiaodan",
      editor = "Webber, Bonnie  and
            Cohn, Trevor  and
            He, Yulan  and
            Liu, Yang",
      booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      month = nov,
      year = "2020",
      address = "Online",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2020.emnlp-main.742",
      doi = "10.18653/v1/2020.emnlp-main.742",
      pages = "9230--9240",
      abstract = "Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, GRADE incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgments. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.",
      environments = {text},
      agents = {two_agents},
      evaluation = {human, model_based},
      other = {human_agent}
}

@inproceedings{mehri-eskenazi-2020-unsupervised,
      title = "Unsupervised Evaluation of Interactive Dialog with {D}ialo{GPT}",
      author = "Mehri, Shikib  and
            Eskenazi, Maxine",
      editor = "Pietquin, Olivier  and
            Muresan, Smaranda  and
            Chen, Vivian  and
            Kennington, Casey  and
            Vandyke, David  and
            Dethlefs, Nina  and
            Inoue, Koji  and
            Ekstedt, Erik  and
            Ultes, Stefan",
      booktitle = "Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
      month = jul,
      year = "2020",
      address = "1st virtual meeting",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2020.sigdial-1.28",
      doi = "10.18653/v1/2020.sigdial-1.28",
      pages = "225--235",
      abstract = "It is important to define meaningful and interpretable automatic evaluation metrics for open-domain dialog research. Standard language generation metrics have been shown to be ineffective for dialog. This paper introduces the FED metric (fine-grained evaluation of dialog), an automatic evaluation metric which uses DialoGPT, without any fine-tuning or supervision. It also introduces the FED dataset which is constructed by annotating a set of human-system and human-human conversations with eighteen fine-grained dialog qualities. The FED metric (1) does not rely on a ground-truth response, (2) does not require training data and (3) measures fine-grained dialog qualities at both the turn and whole dialog levels. FED attains moderate to strong correlation with human judgement at both levels.",
      environments = {text},
      agents = {two_agents},
      evaluation = {human, model_based},
      other = {human_agent}
}

#### Evaluating embodied social agents
@article{evaluation/embodied,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@inproceedings{min-etal-2022-dont,
    title = "Don{'}t Copy the Teacher: Data and Model Challenges in Embodied Dialogue",
    author = "Min, So Yeon  and
      Zhu, Hao  and
      Salakhutdinov, Ruslan  and
      Bisk, Yonatan",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.635",
    doi = "10.18653/v1/2022.emnlp-main.635",
    pages = "9361--9368",
    abstract = "Embodied dialogue instruction following requires an agent to complete a complex sequence of tasks from a natural language exchange. The recent introduction of benchmarks raises the question of how best to train and evaluate models for this multi-turn, multi-agent, long-horizon task. This paper contributes to that conversation, by arguing that imitation learning (IL) and related low-level metrics are actually misleading and do not align with the goals of embodied dialogue research and may hinder progress. We provide empirical comparisons of metrics, analysis of three models, and make suggestions for how the field might best progress. First, we observe that models trained with IL take spurious actions during evaluation. Second, we find that existing models fail to ground query utterances, which are essential for task completion. Third, we argue evaluation should focus on higher-level semantic goals. We will release code to additionally filter the data and benchmark models for improved evaluation.",
  environments={mixed_objectives, collaboration, embodied},
  agents={agents_with_memory},
  evaluation={qualitative, human, rule_based},
  other={n/a}
}

@misc{guo2024embodied,
      title={Embodied LLM Agents Learn to Cooperate in Organized Teams}, 
      author={Xudong Guo and Kaixuan Huang and Jiale Liu and Wenhui Fan and Natalia Vélez and Qingyun Wu and Huazheng Wang and Thomas L. Griffiths and Mengdi Wang},
      year={2024},
      month={3},
      environments = {collaboration, embodied},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {model_based, human},
      url={https://arxiv.org/abs/2403.12482},
      other = {education},
      eprint={2403.12482},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}



@article{10.1145/3476413,
author = {Biswas, Abhijat and Wang, Allan and Silvera, Gustavo and Steinfeld, Aaron and Admoni, Henny},
title = {SocNavBench: A Grounded Simulation Testing Framework for Evaluating Social Navigation},
year = {2022},
month={2},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
url = {https://doi.org/10.1145/3476413},
doi = {10.1145/3476413},
abstract = {The human-robot interaction community has developed many methods for robots to navigate safely and socially alongside humans. However, experimental procedures to evaluate these works are usually constructed on a per-method basis. Such disparate evaluations make it difficult to compare the performance of such methods across the literature. To bridge this gap, we introduce SocNavBench, a simulation framework for evaluating social navigation algorithms. SocNavBench comprises a simulator with photo-realistic capabilities and curated social navigation scenarios grounded in real-world pedestrian data. We also provide an implementation of a suite of metrics to quantify the performance of navigation algorithms on these scenarios. Altogether, SocNavBench provides a test framework for evaluating disparate social navigation methods in a consistent and interpretable manner. To illustrate its use, we demonstrate testing three existing social navigation methods and a baseline method on SocNavBench, showing how the suite of metrics helps infer their performance trade-offs. Our code is open-source, allowing the addition of new scenarios and metrics by the community to help evolve SocNavBench to reflect advancements in our understanding of social navigation.},
journal = {J. Hum.-Robot Interact.},
month = {jul},
articleno = {26},
numpages = {24},
keywords = {Benchmark, social navigation, pedestrian, human robot interaction},
      environments={implicit_objectives, embodied},
      agents={reinforcement_learning},
      evaluation={rule_based},
      other={simulated_humans}
}


@inproceedings{10.5555/3463952.3464159,
author = {Knott, Paul and Carroll, Micah and Devlin, Sam and Ciosek, Kamil and Hofmann, Katja and Dragan, Anca and Shah, Rohin},
title = {Evaluating the Robustness of Collaborative Agents},
year = {2021},
month={1},
url={https://dl.acm.org/doi/abs/10.5555/3463952.3464159},
isbn = {9781450383073},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Artificial agents trained by deep reinforcement learning will likely encounter novel situations after deployment that were never seen during training. Our agent must be robust to handle such situations well. However, if we cannot rely on the average training or validation reward as a metric, then how can we effectively evaluate robustness? We take inspiration from the practice of unit testing in software engineering. Specifically, we suggest that when designing AI agents that collaborate with humans, designers should search for potential edge cases in possible partner behavior and possible states encountered, and write tests which check that the behavior of the agent in these edge cases is reasonable. We apply this methodology to build a suite of unit tests for the Overcooked-AI environment, and use this test suite to evaluate three proposals for improving robustness. We find that the test suite provides significant insight into the effects of these proposals that were generally not revealed by looking solely at the average validation reward. For our full paper, see https://arxiv.org/abs/2101.05507 arxiv.org/abs/2101.05507},
booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1560–1562},
numpages = {3},
keywords = {human-AI collaboration, multi-agent RL, robustness},
location = {Virtual Event, United Kingdom},
series = {AAMAS '21},
      environments={collaboration, embodied},
      agents={reinforcement_learning},
      evaluation={rule_based},
      other={n/a}
}





=======
@misc{singh2024change,
      title={How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning}, 
      author={Siddarth Singh and Omayma Mahjoub and Ruan de Kock and Wiem Khlifi and Abidine Vall and Kale-ab Tessera and Arnu Pretorius},
      year={2024},
      eprint={2312.08463},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      environments = {collaboration, embodied},
      agents = {reinforcement_learning, more_than_three_agents},
      evaluation = {rule_based},
      other = {n/a},
      url = {https://arxiv.org/abs/2312.08463}
}

@inproceedings{leibo2021scalable,
  title={Scalable evaluation of multi-agent reinforcement learning with melting pot},
  author={Leibo, Joel Z and Due{\~n}ez-Guzman, Edgar A and Vezhnevets, Alexander and Agapiou, John P and Sunehag, Peter and Koster, Raphael and Matyas, Jayd and Beattie, Charlie and Mordatch, Igor and Graepel, Thore},
  booktitle={International conference on machine learning},
  pages={6187--6199},
  year={2021},
  organization={PMLR},
  environments = {collaboration, competition, mixed_objectives, embodied},
  agents = {reinforcement_learning, more_than_three_agents},
  evaluation = {rule_based},
  other = {n/a},
  month = {7},
  url={https://proceedings.mlr.press/v139/leibo21a.html}
}

@inproceedings{bara-etal-2021-mindcraft,
    title = "{M}ind{C}raft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks",
    author = "Bara, Cristian-Paul  and
      CH-Wang, Sky  and
      Chai, Joyce",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.85",
    pages = "1112--1125",
    abstract = "An ideal integration of autonomous agents in a human world implies that they are able to collaborate on human terms. In particular, theory of mind plays an important role in maintaining common ground during human collaboration and communication. To enable theory of mind modeling in situated interactions, we introduce a fine-grained dataset of collaborative tasks performed by pairs of human subjects in the 3D virtual blocks world of Minecraft. It provides information that captures partners{'} beliefs of the world and of each other as an interaction unfolds, bringing abundant opportunities to study human collaborative behaviors in situated language communication. As a first step towards our goal of developing embodied AI agents able to infer belief states of collaborative partners in situ, we build and present results on computational models for several theory of mind tasks.",
    environments = {collaboration, embodied},
    agents = {finetuning, two_agents},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@inproceedings{narayan-chen-etal-2019-collaborative,
    title = "Collaborative Dialogue in {M}inecraft",
    author = "Narayan-Chen, Anjali  and
      Jayannavar, Prashant  and
      Hockenmaier, Julia",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1537",
    doi = "10.18653/v1/P19-1537",
    pages = "5405--5415",
    abstract = "We wish to develop interactive agents that can communicate with humans to collaboratively solve tasks in grounded scenarios. Since computer games allow us to simulate such tasks without the need for physical robots, we define a Minecraft-based collaborative building task in which one player (A, the Architect) is shown a target structure and needs to instruct the other player (B, the Builder) to build this structure. Both players interact via a chat interface. A can observe B but cannot place blocks. We present the Minecraft Dialogue Corpus, a collection of 509 conversations and game logs. As a first step towards our goal of developing fully interactive agents for this task, we consider the subtask of Architect utterance generation, and show how challenging it is.",
    environments = {collaboration, embodied},
    agents = {two_agents},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@inproceedings{ichikawa-higashinaka-2022-analysis,
    title = "Analysis of Dialogue in Human-Human Collaboration in {M}inecraft",
    author = "Ichikawa, Takuma  and
      Higashinaka, Ryuichiro",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.431",
    pages = "4051--4059",
    abstract = "Recently, many studies have focused on developing dialogue systems that enable collaborative work; however, they rarely focus on creative tasks. Collaboration for creative work, in which humans and systems collaborate to create new value, will be essential for future dialogue systems. In this study, we collected 500 dialogues of human-human collaboration in Minecraft as a basis for developing a dialogue system that enables creative collaborative work. We conceived the Collaborative Garden Task, where two workers interact and collaborate in Minecraft to create a garden, and we collected dialogue, action logs, and subjective evaluations. We also collected third-person evaluations of the gardens and analyzed the relationship between dialogue and collaborative work that received high scores on the subjective and third-person evaluations in order to identify dialogic factors for high-quality collaborative work. We found that two essential aspects in creative collaborative work are performing more processes to ask for and agree on suggestions between workers and agreeing on a particular image of the final product in the early phase of work and then discussing changes and details.",
    environments = {collaboration, embodied},
    agents = {two_agents},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@InProceedings{CordialSync,
  author = {Jain, Unnat and Weihs, Luca and Kolve, Eric and Farhadi, Ali and Lazebnik, Svetlana and Kembhavi, Aniruddha and Schwing, Alexander G.},
  title = {A Cordial Sync: Going Beyond Marginal Policies For Multi-Agent Embodied Tasks},
  booktitle = {ECCV},
  year = {2020},
  month={11},
  note = {first two authors contributed equally},
  environments = {collaboration, embodied},
  agents = {finetuning, reinforcement_learning, two_agents},
  evaluation = {rule_based},
  other = {n/a},
  url = {https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500460.pdf},
}

@InProceedings{TwoBody,
  author = {Jain, Unnat and Weihs, Luca and Kolve, Eric and Rastegari, Mohammad and Lazebnik, Svetlana and Farhadi, Ali and Schwing, Alexander G. and Kembhavi, Aniruddha},
  title = {Two Body Problem: Collaborative Visual Task Completion},
  booktitle = {CVPR},
  year = {2019},
  month = {6},
  note = {first two authors contributed equally},
  environments = {collaboration, embodied},
  agents = {finetuning, reinforcement_learning, two_agents},
  evaluation = {rule_based},
  other = {n/a},
  url = {https://openaccess.thecvf.com/content_CVPR_2019/papers/Jain_Two_Body_Problem_Collaborative_Visual_Task_Completion_CVPR_2019_paper.pdf},
}

@inproceedings{teach,
  title={{TEACh: Task-driven Embodied Agents that Chat}},
  author={Padmakumar, Aishwarya and Thomason, Jesse and Shrivastava, Ayush and Lange, Patrick and Narayan-Chen, Anjali and Gella, Spandana and Piramuthu, Robinson and Tur, Gokhan and Hakkani-Tur, Dilek},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={2},
  pages={2017--2025},
  year={2022},
  month={2},
  environments = {collaboration, embodied},
  agents = {finetuning, two_agents},
  evaluation = {rule_based},
  other = {human_agent},
  url = {https://arxiv.org/abs/2110.00534}
}

@inproceedings{teachda,
  title={{Dialog Acts for Task-Driven Embodied Agents}},
  author={Gella, Spandana and Padmakumar, Aishwarya and Lange, Patrick and Hakkani-Tur, Dilek},
  booktitle={Proceedings of the 23nd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDial)},
  year={2022},
  pages={111-123},
  month={9},
  environments = {collaboration, embodied},
  agents = {finetuning, two_agents},
  evaluation = {rule_based},
  other = {human_agent},
  url = {https://aclanthology.org/2022.sigdial-1.13},
}

@inproceedings{kim2016evaluation,
  title={Evaluation of starcraft artificial intelligence competition bots by experienced human players},
  author={Kim, Man-Je and Kim, Kyung-Joong and Kim, SeungJun and Dey, Anind K},
  booktitle={Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  pages={1915--1921},
  year={2016},
  month={5},
  environments = {collaboration, competition, mixed_objectives, embodied},
  agents = {more_than_three_agents},
  evaluation = {human, rule_based},
  other = {human_agent},
  url = {https://dl.acm.org/doi/pdf/10.1145/2851581.2892305},
}


#### Evaluating virtual social agents
@article{evaluation/virtual,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

#### Evaluating robotics in social contexts
@article{evaluation/robotics,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@misc{sferrazza2024humanoidbench,
    title={HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation}, 
    author={Carmelo Sferrazza and Dun-Ming Huang and Xingyu Lin and Youngwoon Lee and Pieter Abbeel},
    year={2024},
    month={3},
    url={https://arxiv.org/abs/2403.10506},
    eprint={2403.10506},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, model_based},
    other = {human_agent, simulated_humans}
}

@INPROCEEDINGS{1174284,
    author={Scholtz, J.},
    booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, 
    title={Theory and evaluation of human robot interactions}, 
    year={2003},
    month={1},
    url={https://ieeexplore.ieee.org/document/1174284},
    volume={},
    number={},
    pages={10 pp.-},
    keywords={Human robot interaction;Robot sensing systems;Mobile robots;Software architecture;NIST;Feeds;User interfaces;Computer architecture;Human computer interaction;Man machine systems},
    doi={10.1109/HICSS.2003.1174284},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human},
    other = {human_agent}
  
}
  
@inproceedings{10.1145/1121241.1121249,
    author = {Steinfeld, Aaron and Fong, Terrence and Kaber, David and Lewis, Michael and Scholtz, Jean and Schultz, Alan and Goodrich, Michael},
    title = {Common metrics for human-robot interaction},
    year = {2006},
    month = {3},
    isbn = {1595932941},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1121241.1121249},
    doi = {10.1145/1121241.1121249},
    abstract = {This paper describes an effort to identify common metrics for task-oriented human-robot interaction (HRI). We begin by discussing the need for a toolkit of HRI metrics. We then describe the framework of our work and identify important biasing factors that must be taken into consideration. Finally, we present suggested common metrics for standardization and a case study. Preparation of a larger, more detailed toolkit is in progress.},
    booktitle = {Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction},
    pages = {33–40},
    numpages = {8},
    keywords = {unmanned ground vehicles, metrics, human-robot interaction},
    location = {Salt Lake City, Utah, USA},
    series = {HRI '06},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based, model_based},
    other = {human_agent}
}

@article{zacharaki2020safety,
    title={Safety bounds in human robot interaction: A survey},
    author={Zacharaki, Angeliki and Kostavelis, Ioannis and Gasteratos, Antonios and Dokas, Ioannis},
    journal={Safety science},
    volume={127},
    pages={104667},
    year={2020},
    month = {7},
    publisher={Elsevier},
    url = {https://www.sciencedirect.com/science/article/pii/S0925753520300643},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{hancock2011meta,
    title={A meta-analysis of factors affecting trust in human-robot interaction},
    author={Hancock, Peter A and Billings, Deborah R and Schaefer, Kristin E and Chen, Jessie YC and De Visser, Ewart J and Parasuraman, Raja},
    journal={Human factors},
    volume={53},
    number={5},
    pages={517--527},
    year={2011},
    month={10},
    url={https://journals.sagepub.com/doi/10.1177/0018720811417254},
    publisher={Sage Publications Sage CA: Los Angeles, CA},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{bartneck2009measurement,
    title={Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots},
    author={Bartneck, Christoph and Kuli{\'c}, Dana and Croft, Elizabeth and Zoghbi, Susana},
    journal={International journal of social robotics},
    volume={1},
    pages={71--81},
    year={2009},
    month={11},
    publisher={Springer},
    url={https://link.springer.com/article/10.1007/s12369-008-0001-3},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{iocchi2015robocup,
    title={RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots},
    author={Iocchi, Luca and Holz, Dirk and Ruiz-del-Solar, Javier and Sugiura, Komei and Van Der Zant, Tijn},
    journal={Artificial Intelligence},
    volume={229},
    pages={258--281},
    year={2015},
    month={12},
    url={https://www.sciencedirect.com/science/article/pii/S0004370215001174},
    publisher={Elsevier},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{doi:10.1080/01691864.2019.1698462,
    author = {Y. Mizuchi and T. Inamura},
    title = {Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition},
    journal = {Advanced Robotics},
    volume = {34},
    number = {3-4},
    pages = {142--156},
    year = {2020},
    month = {12},
    publisher = {Taylor \& Francis},
    doi = {10.1080/01691864.2019.1698462},
    url = {https://doi.org/10.1080/01691864.2019.1698462},
    environments = {competition, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}
### Interactions with humans

#### Human-Chatbot Interaction
@article{interactions/text,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@inproceedings{rapp2023collaborating,
  title={Collaborating with a Text-Based Chatbot: An Exploration of Real-World Collaboration Strategies Enacted during Human-Chatbot Interactions},
  author={Rapp, Amon and Boldi, Arianna and Curti, Lorenzo and Perrucci, Alessandro and Simeoni, Rossana},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  month={4},
  year={2023},
  url={https://dl.acm.org/doi/pdf/10.1145/3544548.3580995},
  environments = {text},
  agents = {prompting_and_in_context_learning},
  evaluation = {qualitative},
  other = {human_agent}
}

@inproceedings{pillis2024ai,
  title={AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy},
  author={Pillis, Daniel and Pataranutaporn, Pat and Maes, Pattie and Sra, Misha},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={686--698},
  month={3},
  year={2024},
  url={https://dl.acm.org/doi/pdf/10.1145/3640543.3645213},
  environments = {text},
  agents = {prompting_and_in_context_learning},
  evaluation = {qualitative},
  other = {human_agent}
}

@inproceedings{lee2023exploring,
  title={Exploring effects of chatbot-based social contact on reducing mental illness stigma},
  author={Lee, Yi-Chieh and Cui, Yichao and Jamieson, Jack and Fu, Wayne and Yamashita, Naomi},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  url={https://dl.acm.org/doi/pdf/10.1145/3544548.3581384},
  pages={1--16},
  month={4},
  year={2023},
  environments = {text},
  agents = {prompting_and_in_context_learning},
  evaluation = {qualitative, human},
  other = {human_agent, health}
}

@inproceedings{jang2024s,
  title={" It's the only thing I can trust": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance},
  author={Jang, JiWoong and Moharana, Sanika and Carrington, Patrick and Begel, Andrew},
  journal={arXiv preprint arXiv:2403.03297},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  month={5},
  year={2024},
  url={https://arxiv.org/pdf/2403.03297.pdf},
  environments = {text},
  agents = {prompting_and_in_context_learning},
  evaluation = {qualitative, human},
  other = {human_agent}
}

@inproceedings{volkel2022user,
  title={User perceptions of extraversion in chatbots after repeated use},
  author={V{\"o}lkel, Sarah Theres and Schoedel, Ramona and Kaya, Lale and Mayer, Sven},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  month={4},
  year={2022},
  url={https://dl.acm.org/doi/pdf/10.1145/3491102.3502058},
  environments = {text},
  agents = {n/a},
  evaluation = {human},
  other = {human_agent}
}

@inproceedings{kuhail2022interacting,
  title={Interacting with a chatbot-based advising system: Understanding the effect of chatbot personality and user gender on behavior},
  author={Kuhail, Mohammad Amin and Thomas, Justin and Alramlawi, Salwa and Shah, Syed Jawad Hussain and Thornquist, Erik},
  booktitle={Informatics},
  volume={9},
  number={4},
  pages={81},
  month={9},
  year={2022},
  organization={MDPI},
  url={https://www.mdpi.com/2227-9709/9/4/81},
  environments = {text},
  agents = {n/a},
  evaluation = {qualitative, human},
  other = {human_agent, education}
}

@inproceedings{kim2023effects,
  title={The Effects of Engaging and Affective Behaviors of Virtual Agents in Group Decision-Making},
  author={Kim, Hanseob and Han, Bin and Kim, Jieun and Syawaludin, Muhammad Firdaus and Kim, Gerard Jounghyun and Hwang, Jae-In},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  month={5},
  year={2023},
  url={https://arxiv.org/pdf/2308.10385.pdf},
  environments = {embodied},
  agents = {n/a},
  evaluation = {human},
  other = {human_agent}
}

@inproceedings{qian2024take,
  title={Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration},
  author={Qian, Crystal and Wexler, James},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={370--384},
  month={3},
  year={2024},
  url={https://dl.acm.org/doi/pdf/10.1145/3640543.3645198},
  environments = {text},
  agents = {prompting_and_in_context_learning},
  evaluation = {human, qualitative},
  other = {human_agent}
}

#### Human-Embodied Agent Interaction
@article{interactions/embodied,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}


@inproceedings{puig2023nopa,
  title={Nopa: Neurally-guided online probabilistic assistance for building socially intelligent home assistants},
  author={Puig, Xavier and Shu, Tianmin and Tenenbaum, Joshua B and Torralba, Antonio},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7628--7634},
  year={2023},
  month = {1},
  organization={IEEE},
  url={https://ieeexplore.ieee.org/document/10161352},
  environments={collaboration, embodied},
  agents={reinforcement_learning},
  evaluation={rule_based},
  other={n/a}
}

@inproceedings{puig2021watchandhelp,
title={Watch-And-Help: A Challenge for Social Perception and Human-{\{}AI{\}} Collaboration},
author={Xavier Puig and Tianmin Shu and Shuang Li and Zilin Wang and Yuan-Hong Liao and Joshua B. Tenenbaum and Sanja Fidler and Antonio Torralba},
booktitle={International Conference on Learning Representations},
year={2021},
month={1},
url={https://openreview.net/forum?id=w_7JMpGZRh0},
  environments={collaboration, embodied},
  agents={reinforcement_learning},
  evaluation={rule_based},
  other={n/a}
}


@article{carroll2019utility,
  title={On the utility of learning about humans for human-ai coordination},
  author={Carroll, Micah and Shah, Rohin and Ho, Mark K and Griffiths, Tom and Seshia, Sanjit and Abbeel, Pieter and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019},
  month={10},
  url={https://proceedings.neurips.cc/paper_files/paper/2019/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf},
  environments={collaboration, embodied},
  agents={reinforcement_learning},
  evaluation={rule_based},
  other={n/a}
}

@inproceedings{nalepka2021interaction,
  title={Interaction flexibility in artificial agents teaming with humans},
  author={Nalepka, Patrick and Gregory-Dunsmore, Jordan P and Simpson, James and Patil, Gaurav and Richardson, Michael J},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={43},
  number={43},
  year={2021},
  month={5},
  url={https://escholarship.org/uc/item/9ks6n70q},
  environments={collaboration, embodied},
  agents={reinforcement_learning},
  evaluation={rule_based},
  other={n/a}
}

@article{liu2023llm,
  title={Llm-powered hierarchical language agent for real-time human-ai coordination},
  author={Liu, Jijia and Yu, Chao and Gao, Jiaxuan and Xie, Yuqing and Liao, Qingmin and Wu, Yi and Wang, Yu},
  journal={arXiv preprint arXiv:2312.15224},
  year={2023},
  month={12},
  url={https://arxiv.org/abs/2312.15224},
  environments={collaboration, embodied},
  agents={reinforcement_learning},
  evaluation={rule_based},
  other={n/a}
}

@inproceedings{szot2023adaptive,
  title={Adaptive coordination in social embodied rearrangement},
  author={Szot, Andrew and Jain, Unnat and Batra, Dhruv and Kira, Zsolt and Desai, Ruta and Rai, Akshara},
  booktitle={International Conference on Machine Learning},
  pages={33365--33380},
  year={2023},
  month={5},
  organization={PMLR},
  url={https://proceedings.mlr.press/v202/szot23a/szot23a.pdf},
  environments={collaboration, embodied},
  agents={prompting_and_in_context_learning},
  evaluation={rule_based},
  other={n/a}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023},
  month={4},
  url={https://dl.acm.org/doi/abs/10.1145/3586183.3606763},
  environments={mixed_objectives, embodied},
  agents={prompting_and_in_context_learning},
  evaluation={rule_based},
  other={n/a}
}


#### Human Robot Interaction
@article{interactions/robot,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

#### Human-Human Interaction
@article{interactions/human,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

### Challenges

#### Theory of Mind

#### Social Learning

#### Simultaneous Interaction

### Applications

#### Health
@article{applications/health,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@misc{mukherjee2024polaris,
      title={Polaris: A Safety-focused LLM Constellation Architecture for Healthcare}, 
      author={Subhabrata Mukherjee and Paul Gamble and Markel Sanz Ausin and Neel Kant and Kriti Aggarwal and Neha Manjunath and Debajyoti Datta and Zhengliang Liu and Jiayuan Ding and Sophia Busacca and Cezanne Bianco and Swapnil Sharma and Rae Lasko and Michelle Voisard and Sanchay Harneja and Darya Filippova and Gerry Meixiong and Kevin Cha and Amir Youssefi and Meyhaa Buvanesh and Howard Weingram and Sebastian Bierman-Lytle and Harpreet Singh Mangat and Kim Parikh and Saad Godil and Alex Miller},
      year={2024},
      environments = {mixed_objectives, virtual},
      agents = {prompting_and_in_context_learning, finetuning, reinforcement_learning, agent_teams},
      evaluation = {human, rule_based},
      url={https://arxiv.org/abs/2403.13313},
      other = {human_agent, health},
      eprint={2403.13313},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{ke2024enhancing,
      title={Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias}, 
      author={Yu He Ke and Rui Yang and Sui An Lie and Taylor Xin Yi Lim and Hairil Rizal Abdullah and Daniel Shu Wei Ting and Nan Liu},
      year={2024},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, agent_teams, agents_with_personas},
      evaluation = {human},
      url={https://arxiv.org/abs/2401.14589},
      other = {simulated_humans, health},
      eprint={2401.14589},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{huang2024benchmarking,
      title={Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset}, 
      author={Hengguan Huang and Songtao Wang and Hongfu Liu and Hao Wang and Ye Wang},
      year={2024},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, finetuning, agent_teams},
      evaluation = {human, rule_based},
      url={https://arxiv.org/abs/2402.05547},
      other = {human_agent, health},
      eprint={2402.05547},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{fan2024ai,
      title={AI Hospital: Interactive Evaluation and Collaboration of LLMs as Intern Doctors for Clinical Diagnosis}, 
      author={Zhihao Fan and Jialong Tang and Wei Chen and Siyuan Wang and Zhongyu Wei and Jun Xi and Fei Huang and Jingren Zhou},
      year={2024},
      environments = {collaboration, text},
      agents = {prompting_and_in_context_learning, agent_teams, agents_with_personas},
      evaluation = {human},
      url={https://arxiv.org/abs/2402.09742},
      other = {simulated_humans, health},
      eprint={2402.09742},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lee2024cocoa,
      title={COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt}, 
      author={Suyeon Lee and Jieun Kang and Harim Kim and Kyoung-Mee Chung and Dongha Lee and Jinyoung Yeo},
      year={2024},
      environments = {text},
      agents = {prompting_and_in_context_learning, two_agents, agents_with_memory},
      evaluation = {model_based},
      url={https://arxiv.org/abs/2402.17546},
      other = {health},
      eprint={2402.17546},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{hsu2023helping,
      title={Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback}, 
      author={Shang-Ling Hsu and Raj Sanjay Shah and Prathik Senthil and Zahra Ashktorab and Casey Dugan and Werner Geyer and Diyi Yang},
      year={2023},
      environments = {text},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {human},
      url={https://arxiv.org/abs/2305.08982},
      other = {human_agent, health},
      eprint={2305.08982},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@misc{qin2023read,
      title={Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media}, 
      author={Wei Qin and Zetong Chen and Lei Wang and Yunshi Lan and Weijieying Ren and Richang Hong},
      year={2023},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, two_agents},
      evaluation = {n/a},
      url={https://arxiv.org/abs/2305.05138},
      other = {human_agent, health},
      eprint={2305.05138},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

 @article{görtz_2023, 
      title={An artificial intelligence-based chatbot for prostate cancer education: Design and patient evaluation study}, 
      volume={9}, 
      url={https://pubmed.ncbi.nlm.nih.gov/37152238/}, 
      DOI={https://doi.org/10.1177/20552076231173304}, 
      journal={Digital Health}, 
      author={Görtz, Magdalena and Baumgärtner, Kilian and Schmid, Tamara and Muschko, Marc and Woessner, Philipp and Gerlach, Axel and Byczkowski, Michael and Sültmann, Holger and Duensing, Stefan and Hohenfellner, Markus}, 
      environments = {text},
      agents = {finetuning, two_agents},
      evaluation = {qualitative},
      other = {human_agent, health},
      month={05},
      year={2023}, 
      pages={20552076231173304} 
 }

 @misc{abbasian2024conversational,
      title={Conversational Health Agents: A Personalized LLM-Powered Agent Framework}, 
      author={Mahyar Abbasian and Iman Azimi and Amir M. Rahmani and Ramesh Jain},
      year={2024},
      environments = {mixed_objectives, text},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {rule_based},
      url={https://arxiv.org/abs/2310.02374},
      other = {human_agent, health},
      eprint={2310.02374},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
 }


#### Policy
@article{applications/policy,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@inproceedings{10.1145/3526113.3545616,
author = {Park, Joon Sung and Popowski, Lindsay and Cai, Carrie and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
title = {Social Simulacra: Creating Populated Prototypes for Social Computing Systems},
year = {2022},
isbn = {9781450393201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526113.3545616},
doi = {10.1145/3526113.3545616},
booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
articleno = {74},
numpages = {18},
keywords = {social computing, prototyping},
location = {Bend, OR, USA},
series = {UIST '22},
environments = {text, implicit_objectives},
agents = {more_than_three_agents},
evaluation = {human},
other = {policy},
month = {8}
}

@misc{tjuatja2024llms,
      title={Do LLMs exhibit human-like response biases? A case study in survey design}, 
      author={Lindia Tjuatja and Valerie Chen and Sherry Tongshuang Wu and Ameet Talwalkar and Graham Neubig},
      year={2024},
      eprint={2311.04076},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
        url={https://arxiv.org/abs/2311.04076},
        environments = {text},
        agents = {prompting_and_in_context_learning},
        evaluation = {human, model_based},
        other = {policy},
}

@misc{wang2024large,
      title={Large language models cannot replace human participants because they cannot portray identity groups}, 
      author={Angelina Wang and Jamie Morgenstern and John P. Dickerson},
      year={2024},
      eprint={2402.01908},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
        url={https://arxiv.org/abs/2402.01908},
        environments = {text},
        agents = {n/a},
        evaluation = {n/a},
        other = {policy},
}

@misc{mou2024unveiling,
      title={Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation}, 
      author={Xinyi Mou and Zhongyu Wei and Xuanjing Huang},
      year={2024},
      eprint={2402.16333},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2402.16333},
      environments = {text},
      agents = {more_than_three_agents},
      evaluation = {model_based},
      other = {policy},
}

@misc{liu2024skepticism,
      title={From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News}, 
      author={Yuhan Liu and Xiuying Chen and Xiaoqing Zhang and Xing Gao and Ji Zhang and Rui Yan},
      year={2024},
      eprint={2403.09498},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
        url={https://arxiv.org/abs/2403.09498},
        environments = {text},
        agents = {more_than_three_agents},
        evaluation = {model_based},
        other = {policy},
}



#### Education
@article{applications/education,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

### Concerns

#### Risks
@article{concerns/risks,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

#### Safety
@article{concerns/safety,
  title = {This is a specical entry for us to automatically determine the subsection of the paper, please put the real entry below this one},
  author = {specical entry},
}

@misc{ruan2023identifying,
      title={Identifying the Risks of LM Agents with an LM-Emulated Sandbox}, 
      author={Yangjun Ruan and Honghua Dong and Andrew Wang and Silviu Pitis and Yongchao Zhou and Jimmy Ba and Yann Dubois and Chris J. Maddison and Tatsunori Hashimoto},
      year={2023},
      eprint={2309.15817},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      environments = {text, virtual},
      agents = {prompting_and_in_context_learning},
      evaluation = {rule_based},
      other = {n/a},
      url={https://arxiv.org/abs/2309.15817},
}

@inproceedings{Lazar2024FrontierAE,
  title={Frontier AI Ethics: Anticipating and Evaluating the Societal Impacts of Generative Agents},
  author={Seth Lazar},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:269033095},
  eprint={2404.06750},
  archivePrefix={arXiv},
  environments = {n/a},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {4},
}

@article{Sharma2023TowardsUS,
  title={Towards Understanding Sycophancy in Language Models},
  author={Mrinank Sharma and Meg Tong and Tomasz Korbak and David Kristjanson Duvenaud and Amanda Askell and Samuel R. Bowman and Newton Cheng and Esin Durmus and Zac Hatfield-Dodds and Scott Johnston and Shauna Kravec and Tim Maxwell and Sam McCandlish and Kamal Ndousse and Oliver Rausch and Nicholas Schiefer and Da Yan and Miranda Zhang and Ethan Perez},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.13548},
  url={https://api.semanticscholar.org/CorpusID:264405698},
  environments = {text},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {10},
}


@article{Turpin2023LanguageMD,
  title={Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
  author={Miles Turpin and Julian Michael and Ethan Perez and Sam Bowman},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.04388},
  url={https://api.semanticscholar.org/CorpusID:258556812},
  environments = {text},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {5},
}

@inproceedings{Liang2021TowardsUA,
  title={Towards Understanding and Mitigating Social Biases in Language Models},
  author={Paul Pu Liang and Chiyu Wu and Louis-Philippe Morency and Ruslan Salakhutdinov},
  booktitle={International Conference on Machine Learning},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:235623756},
  environments = {text},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {6},
}

@article{Mattern2022UnderstandingSI,
  title={Understanding Stereotypes in Language Models: Towards Robust Measurement and Zero-Shot Debiasing},
  author={Justus Mattern and Zhijing Jin and Mrinmaya Sachan and Rada Mihalcea and Bernhard Scholkopf},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.10678},
  url={https://api.semanticscholar.org/CorpusID:254926728},
  environments = {text},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {12},
}

@article{Bai2022ConstitutionalAH,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and John Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and E Perez and Jamie Kerr and Jared Mueller and Jeff Ladish and J Landau and Kamal Ndousse and Kamilė Luko{\vs}iūtė and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noem'i Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Sam Bowman and Zac Hatfield-Dodds and Benjamin Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom B. Brown and Jared Kaplan},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.08073},
  url={https://api.semanticscholar.org/CorpusID:254823489},
  environments = {text},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {12},
}

@article{Park2023AIDA,
  title={AI Deception: A Survey of Examples, Risks, and Potential Solutions},
  author={Peter S. Park and Simon Goldstein and Aidan O'Gara and Michael Chen and Dan Hendrycks},
  journal={ArXiv},
  year={2023},
  volume={abs/2308.14752},
  url={https://api.semanticscholar.org/CorpusID:261276587},
  environments = {text},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {8},
}

@article{Tarsney2024DeceptionAM,
  title={Deception and Manipulation in Generative AI},
  author={Christian Tarsney},
  journal={ArXiv},
  year={2024},
  volume={abs/2401.11335},
  url={https://api.semanticscholar.org/CorpusID:267068787},
  environments = {text},
  agents = {n/a},
  evaluation = {n/a},
  other = {n/a},
  month           = {1},
}

@misc{hendrycks2023overview,
      title={An Overview of Catastrophic AI Risks}, 
      author={Dan Hendrycks and Mantas Mazeika and Thomas Woodside},
      year={2023},
      eprint={2306.12001},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      environments = {n/a},
      agents = {n/a},
      evaluation = {n/a},
      other = {n/a},
      month        = {6},
      url          = {https://arxiv.org/abs/2306.12001},
}

